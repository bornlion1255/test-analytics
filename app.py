import streamlit as st
import pandas as pd
import numpy as np
import requests
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==========================================
# 1. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ==========================================
st.set_page_config(page_title="SLA Dashboard Hybrid", layout="wide")

st.markdown("""
    <style>
    .stDataFrame td { white-space: pre-wrap !important; vertical-align: top !important; }
    </style>
""", unsafe_allow_html=True)

# --- –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –°–ï–ö–†–ï–¢–û–í ---
try:
    API_TOKEN = st.secrets["API_TOKEN"]
    SHEET_ID = st.secrets["SHEET_ID"]
    GID = st.secrets["GID"]
    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ä–æ–ª—å
    SECRET_PASSWORD = st.secrets["PASSWORD"]
except KeyError as e:
    st.error(f"‚ùå –û–®–ò–ë–ö–ê –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò: –í –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö Secrets –Ω–µ –Ω–∞–π–¥–µ–Ω –∫–ª—é—á {e}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª secrets.toml.")
    st.stop()
except Exception as e:
    st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å–µ–∫—Ä–µ—Ç–æ–≤: {e}")
    st.stop()

# –ö–û–ù–°–¢–ê–ù–¢–´
BASE_URL = "https://api.chat2desk.com/v1"
HEADERS = {"Authorization": API_TOKEN}
SHEET_URL = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={GID}"

MAX_WORKERS = 20
TIME_OFFSET = 3

# –°–ü–†–ê–í–û–ß–ù–ò–ö–ò
OPERATORS_MAP = {310507: "–ë–æ—Ç AI", 0: "–°–∏—Å—Ç–µ–º–∞"}
DEPARTMENT_MAPPING = {
    "–ê–ª–∏–Ω–∞ –§–µ–¥—É–ª–æ–≤–∞": "–¢—Ä–µ–Ω–µ—Ä",
    "–ò–ª—å—è –ê–≤—Ä–∞–º–æ–≤": "Appointment",
    "–í–∏–∫—Ç–æ—Ä–∏—è –°—É–≤–æ—Ä–æ–≤–∞": "Appointment",
    "–ö–∏—Ä–∏–ª–ª –ú–∏–Ω–∞–µ–≤": "Appointment",
    "–ú–∞—Ä–∏—è –ü–æ–ø–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–°—Ç–∞–Ω–∏—Å–ª–∞–≤ –ë–∞—Å–æ–≤": "Claims",
    "–ú–∏–ª–µ–Ω–∞ –ì–æ–≤–æ—Ä–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ù–∞–¥–µ–∂–¥–∞ –°–º–∏—Ä–Ω–æ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ò—Ä–∏–Ω–∞ –í–µ—Ä–µ–∂–∞–Ω": "Claims",
    "–ù–∞—Ç–∞–ª—å—è –ü–æ–ª–æ–≤–Ω–∏–∫–æ–≤–∞": "Claims",
    "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–í–ª–∞–¥–∏–º–∏—Ä –ê—Å–∞—Ç—Ä—è–Ω": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –ï—Ä–º–∞–∫–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ì–µ—Ç–º–∞–Ω": "SMM",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –ê–Ω–∏—Å–∏–º–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–û–ª—è –¢—Ä—É—â–µ–ª–µ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ê–ª–∏–Ω–∞ –ù–æ–≤–∏–∫–æ–≤–∞": "SMM",
    "–ò–≤–∞–Ω –°–∞–≤–∏—Ü–∫–∏–π": "SMM",
    "–ê–Ω–∞—Å—Ç–∞—Å–∏—è –í–∞–Ω—è–Ω": "SALE",
    "–ü–∞–≤–µ–ª –ù–æ–≤–∏–∫–æ–≤": "SMM",
    "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞ –®–∞–ø–æ–≤–∞–ª": "SMM",
    "–ì–µ–æ—Ä–≥–∏–π –ê—Å—Ç–∞–ø–æ–≤": "Deep_support",
    "–ï–ª–µ–Ω–∞ –ü–∞–Ω–æ–≤–∞": "Deep_support",
    "–¢–∞—Ç—å—è–Ω–∞ –°–æ—à–Ω–∏–∫–æ–≤–∞": "SMM",
    "–í–∏–∫—Ç–æ—Ä–∏—è –í–æ—Ä–æ–Ω—è–∫": "SMM",
    "–ê–Ω–Ω–∞ –ß–µ—Ä–Ω—ã—à–æ–≤–∞": "SMM",
    "–ê–ª–∏–Ω–∞ –†–µ–±—Ä–∏–Ω–∞": "Claims",
    "–ê–ª–µ–Ω–∞ –í–æ—Ä–æ–Ω–∏–Ω–∞": "Claims",
    "–ö—Å–µ–Ω–∏—è –ë—É—Ö–æ–Ω–∏–Ω–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ï–ª–∏–∑–∞–≤–µ—Ç–∞ –î–∞–≤—ã–¥–µ–Ω–∫–æ": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –ö–æ–Ω–¥—Ä–∞—Ç—å–µ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ö—Å–µ–Ω–∏—è –ì–∞–≤—Ä–∏–ª–æ–≤–∞": "Claims",
    "–°–Ω–µ–∂–∞–Ω–∞ –ï—Ñ–∏–º–æ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ê–Ω–∞—Å—Ç–∞—Å–∏—è –ö–∞—Ä–ø–µ–µ–≤–∞": "Claims",
    "–ö—Ä–∏—Å—Ç–∏–Ω–∞ –õ—é–±–∏–Ω–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ù–∞—Ç–∞–ª—å—è –°–µ—Ä–µ–±—Ä—è–∫–æ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ö–ª–∏—à–∏–Ω": "Claims",
    "–ù–∞—Ç–∞–ª—å—è –ë–∞–ª–∞–Ω–¥–∏–Ω–∞": "Claims",
    "–î–∞–Ω–∏–∏–ª –ì—É—Å–µ–≤": "Appointment",
    "–ù–∏–∫–∏—Ç–∞ –ü—Ä–∏—Ö–æ–¥—å–∫–æ": "Concierge", 
    "–ê–Ω–Ω–∞ –í–ª–∞—Å–µ–Ω–∫–æ–≤–∞": "SMM",
    "–†–µ–≥–∏–Ω–∞ –ê—Ä–µ–Ω–¥—Ç": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –©—É–∫–∏–Ω–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ö—Å–µ–Ω–∏—è –ö—Ä–∏–≤–∫–æ": "Claims",
    "–í–µ—Ä–æ–Ω–∏–∫–∞ –°–æ—Ñ—Ä–æ–Ω–æ–≤–∞": "SMM",
    "–Æ—Ä–∏–π –ö–æ–±–µ–ª–µ–≤": "Claims",
    "–ê—Ä–∏–Ω–∞ –ü—Ä–æ—Ö–æ—Ä–æ–≤–∞": "SMM"
}

CUSTOM_GROUPING = {
    "Cleaner_Payments": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "Penalty": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "Operations": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "Storage": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ"
}

# ==========================================
# 2. –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø (–°–¢–†–û–ì–ê–Ø + –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê)
# ==========================================
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    
    if not st.session_state["password_correct"]:
        st.markdown("### üîê –í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É")
        
        with st.form("credentials"):
            password = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞", type="password")
            submit = st.form_submit_button("–í–æ–π—Ç–∏")
            
            if submit:
                # 1. –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å—ë –∫ —Å—Ç—Ä–æ–∫–∞–º –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
                input_clean = str(password).strip()
                secret_clean = str(SECRET_PASSWORD).strip()
                
                # 2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
                if input_clean == secret_clean:
                    st.session_state["password_correct"] = True
                    st.rerun()
                else:
                    st.error("‚õî –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
                    
                    # --- –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê (–ï–°–õ–ò –ù–ï –†–ê–ë–û–¢–ê–ï–¢ - –†–ê–°–ö–û–ú–ú–ï–ù–¢–ò–†–£–ô–¢–ï –°–¢–†–û–ö–ò –ù–ò–ñ–ï) ---
                    # st.warning(f"–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ (–ø–æ–∫–∞–∂–∏—Ç–µ —ç—Ç–æ –∞–¥–º–∏–Ω—É):")
                    # st.write(f"–û–∂–∏–¥–∞–µ–º–∞—è –¥–ª–∏–Ω–∞ –ø–∞—Ä–æ–ª—è: {len(secret_clean)}")
                    # st.write(f"–í–∞—à–∞ –¥–ª–∏–Ω–∞ –ø–∞—Ä–æ–ª—è: {len(input_clean)}")
                    # st.write(f"–°–∏—Å—Ç–µ–º–∞ –≤–∏–¥–∏—Ç –ø–µ—Ä–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –ø–∞—Ä–æ–ª—è –∫–∞–∫: {secret_clean[:2]}***")
                    # ---------------------------------------------------------------------
                    
        return False
    return True

if not check_password():
    st.stop()

# ==========================================
# 3. –§–£–ù–ö–¶–ò–ò API
# ==========================================
def normalize_text(text):
    if not text: return ""
    return str(text).lower().strip().replace("—ë", "–µ")

def find_department_smart(api_name_full):
    clean_api = normalize_text(api_name_full)
    for name, dept in DEPARTMENT_MAPPING.items():
        if normalize_text(name) == clean_api: return dept
    for name_key, dept in DEPARTMENT_MAPPING.items():
        parts = normalize_text(name_key).split()
        if not parts: continue
        if all(part in clean_api for part in parts): return dept
    return "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"

def format_seconds(x):
    if pd.isna(x) or x is None: return "-"
    try:
        val = int(float(x))
        m, s = divmod(val, 60)
        h, m = divmod(m, 60)
        if h > 0: return f"{h}—á {m}–º"
        return f"{m}–º {s}—Å"
    except: return "-"

def process_single_dialog(item, target_start, target_end):
    req_id = item['req_id']
    try:
        r = requests.get(f"{BASE_URL}/requests/{req_id}/messages", headers=HEADERS, params={"limit": 300})
        if r.status_code != 200: return None
        json_data = r.json()
        msgs = json_data if isinstance(json_data, list) else json_data.get('data', [])
        msgs.sort(key=lambda x: x.get('created', 0))
        
        client_waiting_since = None
        stats = {
            'req_id': req_id,
            'participations': set(),
            'operator_speeds': {},
            'op_hours': {},
            'rating': item.get('rating')
        }
        
        for m in msgs:
            ts = m.get('created')
            if not ts: continue
            dt_utc = pd.to_datetime(ts, unit='s')
            dt_local = dt_utc + timedelta(hours=TIME_OFFSET)
            
            msg_type = m.get('type')
            op_id = m.get('operatorID') or m.get('operator_id')
            
            if msg_type == 'from_client' or msg_type == 'in':
                if client_waiting_since is None: client_waiting_since = dt_local
            
            elif msg_type == 'out' and op_id and op_id != 0 and op_id != 310507:
                 if target_start <= dt_local <= target_end:
                     stats['participations'].add(op_id)
                     
                     if op_id not in stats['op_hours']: stats['op_hours'][op_id] = set()
                     stats['op_hours'][op_id].add(dt_local.hour)
                     
                     if client_waiting_since:
                         diff = (dt_local - client_waiting_since).total_seconds()
                         if diff > 0:
                             if op_id not in stats['operator_speeds']: 
                                 stats['operator_speeds'][op_id] = []
                             stats['operator_speeds'][op_id].append(diff)
                         client_waiting_since = None
                     
        return stats
    except:
        return None

@st.cache_data(ttl=3600)
def load_api_data_range(start_date, end_date):
    try:
        r = requests.get(f"{BASE_URL}/operators", headers=HEADERS, params={"limit": 1000})
        for op in r.json().get('data', []):
            name = f"{op.get('first_name', '')} {op.get('last_name', '')}".strip()
            if not name: name = op.get('email', str(op['id']))
            OPERATORS_MAP[op['id']] = name
    except: pass
    
    all_active_requests = []
    date_list = pd.date_range(start_date, end_date).strftime("%Y-%m-%d").tolist()
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, d_str in enumerate(date_list):
        status_text.text(f"–°–±–æ—Ä —Å–ø–∏—Å–∫–∞ —á–∞—Ç–æ–≤ –∑–∞ {d_str}...")
        limit = 200; offset = 0
        while offset < 5000:
            try:
                params = {"report": "request_stats", "date": d_str, "limit": limit, "offset": offset}
                r = requests.get(f"{BASE_URL}/statistics", headers=HEADERS, params=params)
                data = r.json().get('data', [])
                if not data: break
                for row in data:
                    rating = row.get('rating_scale_score')
                    if rating == 0 or rating == '0': rating = None
                    all_active_requests.append({'req_id': row['request_id'], 'rating': rating})
                if len(data) < limit: break
                offset += limit
            except: break
        progress_bar.progress((i + 1) / (len(date_list) * 2))

    unique_requests = {v['req_id']: v for v in all_active_requests}.values()
    
    final_rows = []
    all_speeds = {}       
    all_first_speeds = {} 
    
    total = len(unique_requests)
    completed = 0
    
    target_start_global = pd.to_datetime(f"{start_date.strftime('%Y-%m-%d')} 00:00:00")
    target_end_global = pd.to_datetime(f"{end_date.strftime('%Y-%m-%d')} 23:59:59")
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_single_dialog, item, target_start_global, target_end_global): item for item in unique_requests}
        for future in as_completed(futures):
            res = future.result()
            if res and res['participations']:
                # –°–±–æ—Ä —Å–∫–æ—Ä–æ—Å—Ç–µ–π
                for op_id, speeds in res['operator_speeds'].items():
                    if op_id not in all_speeds: all_speeds[op_id] = []
                    all_speeds[op_id].extend(speeds)
                    
                    if speeds:
                        if op_id not in all_first_speeds: all_first_speeds[op_id] = []
                        all_first_speeds[op_id].append(speeds[0])

                # –°—Ç—Ä–æ–∫–∏ –¥–ª—è DF
                for op_id in res['participations']:
                    op_name = OPERATORS_MAP.get(op_id, f"ID {op_id}")
                    dept = find_department_smart(op_name)
                    if dept in CUSTOM_GROUPING: dept = CUSTOM_GROUPING[dept]
                    if dept == "–¢—Ä–µ–Ω–µ—Ä": continue
                    
                    hours = res.get('op_hours', {}).get(op_id, set())
                    if not hours:
                        final_rows.append({
                            'req_id': res['req_id'],
                            'operator_id': op_id,
                            '–û–ø–µ—Ä–∞—Ç–æ—Ä': op_name,
                            '–û—Ç–¥–µ–ª': dept,
                            'rating': res['rating'],
                            '–ß–∞—Å': -1
                        })
                    else:
                        for h in hours:
                            final_rows.append({
                                'req_id': res['req_id'],
                                'operator_id': op_id,
                                '–û–ø–µ—Ä–∞—Ç–æ—Ä': op_name,
                                '–û—Ç–¥–µ–ª': dept,
                                'rating': res['rating'],
                                '–ß–∞—Å': h
                            })
            
            completed += 1
            if total > 0: 
                current_prog = 0.5 + (completed / total * 0.5)
                progress_bar.progress(min(current_prog, 1.0))
                status_text.text(f"–ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤: {completed}/{total}")
            
    progress_bar.empty(); status_text.empty()
    
    df = pd.DataFrame(final_rows)
    return df, all_speeds, all_first_speeds

# ==========================================
# 4. GOOGLE SHEET
# ==========================================
@st.cache_data(ttl=600)
def load_gsheet_data():
    try:
        df = pd.read_csv(SHEET_URL)
        df['–î–∞—Ç–∞'] = pd.to_datetime(df['–î–∞—Ç–∞'], dayfirst=True, errors='coerce')
        df = df.dropna(subset=['–î–∞—Ç–∞'])
        for col in ['–û—Ç–¥–µ–ª', '–°—Ç–∞—Ç—É—Å', '–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è']:
            if col in df.columns: df[col] = df[col].astype(str).str.strip()
        df['–ß–∞—Å'] = df['–î–∞—Ç–∞'].dt.hour
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Google Sheet: {e}"); return pd.DataFrame()

# ==========================================
# 5. UI & LOGIC
# ==========================================
st.sidebar.title("–§–∏–ª—å—Ç—Ä—ã")

df_gsheet_all = load_gsheet_data()
if not df_gsheet_all.empty:
    default_min = df_gsheet_all['–î–∞—Ç–∞'].max().date()
    default_max = df_gsheet_all['–î–∞—Ç–∞'].max().date()
else:
    default_min = datetime.now().date()
    default_max = datetime.now().date()

date_range = st.sidebar.date_input(
    "–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç",
    value=(default_min, default_max),
    min_value=df_gsheet_all['–î–∞—Ç–∞'].min().date() if not df_gsheet_all.empty else None,
    max_value=datetime.now().date()
)

if isinstance(date_range, tuple) and len(date_range) == 2:
    sel_start, sel_end = date_range
elif isinstance(date_range, tuple) and len(date_range) == 1:
    sel_start = sel_end = date_range[0]
else:
    sel_start = sel_end = date_range

st.sidebar.caption(f"–í—ã–±—Ä–∞–Ω–æ: {sel_start} ‚Äî {sel_end}")

if st.sidebar.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ (API)"):
    st.session_state['run_analysis'] = True
    st.cache_data.clear()

if 'run_analysis' not in st.session_state:
    st.info("üëà –í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—ã –∏ –Ω–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑'"); st.stop()

# –ó–ê–ì–†–£–ó–ö–ê
df_api, speeds_map, first_speeds_map = load_api_data_range(sel_start, sel_end)

mask_gsheet = (df_gsheet_all['–î–∞—Ç–∞'].dt.date >= sel_start) & (df_gsheet_all['–î–∞—Ç–∞'].dt.date <= sel_end)
df_gsheet = df_gsheet_all[mask_gsheet].copy()

# KPI
if not df_api.empty: count_human_chats = df_api['req_id'].nunique()
else: count_human_chats = 0

bot_closed_mask = (df_gsheet['–°—Ç–∞—Ç—É—Å'].str.lower() == '–∑–∞–∫—Ä—ã–ª')
count_bot_closed = len(df_gsheet[bot_closed_mask])

auth_mask = (df_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].str.contains('–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞', case=False, na=False))
count_auth = len(df_gsheet[auth_mask])

total_chats_day = count_human_chats + count_bot_closed + count_auth

# --- TABS ---
st.title(f"üìä –û—Ç—á–µ—Ç–Ω–æ—Å—Ç—å SLA ({sel_start} ‚Äî {sel_end})")
tabs = st.tabs(["KPI", "–ù–∞–≥—Ä—É–∑–∫–∞", "–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª–∞", "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏", "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö"])

# TAB 1: KPI
with tabs[0]:
    st.subheader("–°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("–í—Å–µ–≥–æ —á–∞—Ç–æ–≤", total_chats_day)
    c2.metric("–õ—é–¥–∏ (API)", count_human_chats)
    c3.metric("–ë–æ—Ç (–ó–∞–∫—Ä—ã–ª)", count_bot_closed)
    c4.metric("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è", count_auth)
    
    st.divider()
    col_pies = st.columns(2)
    with col_pies[0]:
        st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏")
        if total_chats_day > 0:
            fig1, ax1 = plt.subplots(figsize=(4, 4))
            ax1.pie([count_human_chats, count_bot_closed, count_auth], 
                    labels=['–õ—é–¥–∏', '–ë–æ—Ç (–ó–∞–∫—Ä—ã–ª)', '–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è'], 
                    autopct='%1.1f%%', colors=['#66b3ff', '#ff9999', '#99ff99'], startangle=90)
            st.pyplot(fig1, use_container_width=False)
            
    with col_pies[1]:
        st.subheader("–ö–æ–Ω–≤–µ—Ä—Å–∏—è –±–æ—Ç–∞ (–£—á–∞—Å—Ç–∏–µ)")
        bot_participated_df = df_gsheet[df_gsheet['–°—Ç–∞—Ç—É—Å'].isin(['–ó–∞–∫—Ä—ã–ª', '–ü–µ—Ä–µ–≤–æ–¥'])]
        participated_count = len(bot_participated_df)
        transferred_count = participated_count - count_bot_closed
        
        if participated_count > 0:
            st.caption(f"–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –±–æ—Ç–æ–º: {participated_count}")
            fig2, ax2 = plt.subplots(figsize=(4, 4))
            ax2.pie([count_bot_closed, transferred_count], 
                    labels=['–ó–∞–∫—Ä—ã–ª —Å–∞–º', '–ü–µ—Ä–µ–≤–µ–ª –Ω–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞'], 
                    autopct='%1.1f%%', colors=['#ff9999', '#ffcc99'], startangle=90)
            st.pyplot(fig2, use_container_width=False)
        else:
            st.write("–ë–æ—Ç –Ω–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª –≤ –¥–∏–∞–ª–æ–≥–∞—Ö –∑–∞ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥.")

# TAB 2: LOAD
with tabs[1]:
    st.subheader("–ù–∞–≥—Ä—É–∑–∫–∞ –ø–æ –æ—Ç–¥–µ–ª–∞–º (–î–∞–Ω–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç–∞)")
    if not df_api.empty:
        dept_load = df_api.groupby('–û—Ç–¥–µ–ª')['req_id'].nunique().sort_values(ascending=False).reset_index()
        dept_load.columns = ['–û—Ç–¥–µ–ª', '–ö–æ–ª-–≤–æ —á–∞—Ç–æ–≤']
        c_table, c_heat = st.columns([1, 2])
        with c_table: st.dataframe(dept_load, hide_index=True, use_container_width=True)
        with c_heat:
            st.write("**–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞: –û—Ç–¥–µ–ª vs –ß–∞—Å (–î–∞–Ω–Ω—ã–µ API)**")
            
            # –°—Ç—Ä–æ–∏–º –∫–∞—Ä—Ç—É –ø–æ –¥–∞–Ω–Ω—ã–º API
            hm_df = df_api[df_api['–ß–∞—Å'].between(0, 23)]
            
            if not hm_df.empty:
                hm_data = hm_df.groupby(['–û—Ç–¥–µ–ª', '–ß–∞—Å'])['req_id'].nunique().unstack(fill_value=0)
                hm_data = hm_data.reindex(columns=range(24), fill_value=0)
                hm_data['Total'] = hm_data.sum(axis=1)
                hm_data = hm_data.sort_values('Total', ascending=False).drop(columns='Total')

                fig_hm, ax_hm = plt.subplots(figsize=(10, len(hm_data)*0.5+2))
                sns.heatmap(hm_data, annot=True, fmt="d", cmap="YlOrRd", cbar=False, ax=ax_hm)
                ax_hm.set_xlabel("–ß–∞—Å –¥–Ω—è")
                st.pyplot(fig_hm)
            else:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —á–∞—Å–∞–º –≤ API.")

    st.divider()
    st.subheader("–¢–µ–º–∞—Ç–∏–∫–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–í–°–ï –æ–±—Ä–∞—â–µ–Ω–∏—è)")
    topics_df = df_gsheet[~df_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].isin(['–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞'])].copy()
    topics_df['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'] = topics_df['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].replace('-', '–ë–µ–∑ —Ç–µ–º—ã')
    
    if not topics_df.empty:
        top_topics = topics_df['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].value_counts().nlargest(15).index
        topics_df_top = topics_df[topics_df['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].isin(top_topics)]
        hm_topic = topics_df_top.groupby(['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è', '–ß–∞—Å']).size().unstack(fill_value=0)
        hm_topic = hm_topic.reindex(columns=range(24), fill_value=0)
        hm_topic['Total'] = hm_topic.sum(axis=1)
        hm_topic = hm_topic.sort_values('Total', ascending=False).drop(columns='Total')
        
        fig2, ax2 = plt.subplots(figsize=(12, len(hm_topic)*0.6+2))
        sns.heatmap(hm_topic, annot=True, fmt="d", cmap="Blues", cbar=False, ax=ax2)
        st.pyplot(fig2)

# TAB 3: DEPT ANALYSIS
with tabs[2]:
    st.subheader("–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –æ—Ç–¥–µ–ª—É")
    
    if not df_api.empty:
        all_depts = sorted(df_api['–û—Ç–¥–µ–ª'].unique())
        selected_dept = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç–¥–µ–ª", all_depts)
        
        if selected_dept:
            dept_data = df_api[df_api['–û—Ç–¥–µ–ª'] == selected_dept]
            
            unique_ratings = pd.to_numeric(dept_data.drop_duplicates('req_id')['rating'], errors='coerce').dropna()
            
            dept_speeds = []
            operators_in_dept = dept_data['operator_id'].unique()
            for op_id in operators_in_dept:
                if op_id in speeds_map: dept_speeds.extend(speeds_map[op_id])
            
            d_chats = dept_data['req_id'].nunique()
            d_med = np.median(dept_speeds) if dept_speeds else None
            
            d_rate = unique_ratings.mean() if not unique_ratings.empty else 0.0
            d_rate_cnt = len(unique_ratings)
            d_rate_str = f"{d_rate:.2f}" if d_rate_cnt > 0 else "-"
            
            st.markdown(f"""
            ### üìÇ {selected_dept}: {d_chats} —á–∞—Ç–æ–≤
            **(–ü–æ –æ—Ç–¥–µ–ª—É: –°—Ä. —Å–∫–æ—Ä–æ—Å—Ç—å: {format_seconds(d_med)} | –†–µ–π—Ç–∏–Ω–≥: {d_rate_str} ({d_rate_cnt}))**
            """)
            
            st.divider()
            
            # --- –¢–ê–ë–õ–ò–¶–ê –°–ü–ï–¶–ò–ê–õ–ò–°–¢–û–í ---
            st.write("#### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º")
            
            specialist_stats = []
            
            op_list = dept_data.groupby(['operator_id', '–û–ø–µ—Ä–∞—Ç–æ—Ä']).agg(
                chats=('req_id', 'nunique')
            ).reset_index().sort_values('chats', ascending=False)
            
            for i, row in op_list.iterrows():
                op_id = row['operator_id']
                op_name = row['–û–ø–µ—Ä–∞—Ç–æ—Ä']
                cnt = row['chats']
                
                s_first_speeds = first_speeds_map.get(op_id, [])
                s_first_med = np.median(s_first_speeds) if s_first_speeds else None
                s_first_str = format_seconds(s_first_med)
                
                s_speeds = speeds_map.get(op_id, [])
                s_med = np.median(s_speeds) if s_speeds else None
                s_time_str = format_seconds(s_med)
                
                op_ratings = pd.to_numeric(
                    dept_data[dept_data['operator_id'] == op_id]['rating'], 
                    errors='coerce'
                ).dropna()
                
                s_rate_val = op_ratings.mean() if not op_ratings.empty else 0.0
                s_rate_cnt = len(op_ratings)
                s_rate_str = f"{s_rate_val:.2f}" if s_rate_cnt > 0 else "-"
                
                specialist_stats.append({
                    "–û–ø–µ—Ä–∞—Ç–æ—Ä": op_name,
                    "–ß–∞—Ç—ã": cnt,
                    "1-—è —Å–∫–æ—Ä–æ—Å—Ç—å (–º–µ–¥)": s_first_str,
                    "–°—Ä. —Å–∫–æ—Ä–æ—Å—Ç—å (–º–µ–¥)": s_time_str,
                    "–†–µ–π—Ç–∏–Ω–≥": s_rate_str,
                    "–ö–æ–ª-–≤–æ –æ—Ü–µ–Ω–æ–∫": s_rate_cnt
                })
            
            df_spec = pd.DataFrame(specialist_stats)
            st.dataframe(
                df_spec, 
                use_container_width=True, 
                hide_index=True,
                column_config={
                    "–û–ø–µ—Ä–∞—Ç–æ—Ä": st.column_config.TextColumn("–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç"),
                    "–ß–∞—Ç—ã": st.column_config.NumberColumn("–ß–∞—Ç–æ–≤"),
                }
            )

            st.divider()
            
            # –¢–ï–ú–ê–¢–ò–ö–ò
            st.subheader("–¢–µ–º–∞—Ç–∏–∫–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π (GSheet)")
            dept_gsheet = df_gsheet[df_gsheet['–û—Ç–¥–µ–ª'] == selected_dept]
            cat_counts = dept_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].value_counts().reset_index()
            cat_counts.columns = ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ö–æ–ª-–≤–æ']
            
            known = len(dept_gsheet[dept_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'] != '-'])
            unknown = max(0, d_chats - known)
            
            if unknown > 0:
                new_row = pd.DataFrame([{'–ö–∞—Ç–µ–≥–æ—Ä–∏—è': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ (—Ä–∞–∑–Ω–∏—Ü–∞)', '–ö–æ–ª-–≤–æ': unknown}])
                cat_counts = pd.concat([cat_counts, new_row], ignore_index=True)
            
            cat_counts['–î–æ–ª—è'] = (cat_counts['–ö–æ–ª-–≤–æ'] / d_chats * 100).map('{:.1f}%'.format)
            st.dataframe(cat_counts, use_container_width=True, hide_index=True)

# TAB 4 & 5
with tabs[3]:
    st.subheader("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (–ë–æ—Ç)")
    ai_df = df_gsheet[df_gsheet['–°—Ç–∞—Ç—É—Å'].isin(['–ó–∞–∫—Ä—ã–ª', '–ü–µ—Ä–µ–≤–æ–¥'])]
    if not ai_df.empty:
        stats = ai_df.groupby('–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è')['–°—Ç–∞—Ç—É—Å'].value_counts().unstack(fill_value=0)
        for c in ['–ó–∞–∫—Ä—ã–ª', '–ü–µ—Ä–µ–≤–æ–¥']: 
            if c not in stats.columns: stats[c] = 0
        stats['Total'] = stats['–ó–∞–∫—Ä—ã–ª'] + stats['–ü–µ—Ä–µ–≤–æ–¥']
        stats['–ë–æ—Ç(‚úì)'] = (stats['–ó–∞–∫—Ä—ã–ª']/stats['Total']*100).map('{:.1f}%'.format)
        stats['–ë–æ—Ç(‚Üí)'] = (stats['–ü–µ—Ä–µ–≤–æ–¥']/stats['Total']*100).map('{:.1f}%'.format)
        
        tr_df = ai_df[ai_df['–°—Ç–∞—Ç—É—Å'] == '–ü–µ—Ä–µ–≤–æ–¥']
        reasons = ['–¢—Ä–µ–±—É–µ—Ç —Å—Ü–µ–Ω–∞—Ä–∏–π', '–ù–µ –∑–Ω–∞–µ—Ç –æ—Ç–≤–µ—Ç', '–õ–∏–º–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–π']
        r_counts = pd.DataFrame() if tr_df.empty else tr_df.groupby('–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è')['–ü—Ä–∏—á–∏–Ω–∞ –ø–µ—Ä–µ–≤–æ–¥–∞'].value_counts().unstack(fill_value=0)
        for r in reasons: 
            if r not in r_counts.columns: r_counts[r] = 0
        stats = stats.join(r_counts, how='left').fillna(0)
        
        def fmt_r(row):
            tot = row['–ü–µ—Ä–µ–≤–æ–¥']
            if tot == 0: return "-"
            res = [f"‚Ä¢ {r}: {(row.get(r,0)/tot*100):.0f}%" for r in reasons if row.get(r,0) > 0]
            return "\n".join(res) if res else "‚Ä¢ –î—Ä—É–≥–∞—è"
        
        stats['–ü—Ä–∏—á–∏–Ω—ã'] = stats.apply(fmt_r, axis=1)
        final = stats[['Total', '–ë–æ—Ç(‚úì)', '–ë–æ—Ç(‚Üí)', '–ü—Ä–∏—á–∏–Ω—ã']].sort_values('Total', ascending=False).reset_index()
        st.dataframe(final, use_container_width=True, hide_index=True, height=600, column_config={"–ü—Ä–∏—á–∏–Ω—ã": st.column_config.TextColumn(width="medium")})

with tabs[4]:
    st.dataframe(df_gsheet, use_container_width=True)