import streamlit as st
import pandas as pd
import numpy as np
import requests
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px  
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==========================================
# 1. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ==========================================
st.set_page_config(page_title="SLA Dashboard Hybrid", layout="wide")

st.markdown("""
    <style>
    .stDataFrame td { white-space: pre-wrap !important; vertical-align: top !important; }
    </style>
""", unsafe_allow_html=True)

# --- –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –°–ï–ö–†–ï–¢–û–í ---
# –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ (–µ—Å–ª–∏ secrets.toml –Ω–µ—Ç)
API_TOKEN = "cb96240069dfaf99fee34e7bfb1c8b" # –í—Å—Ç–∞–≤—å—Ç–µ —Å—é–¥–∞ —Ç–æ–∫–µ–Ω –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
SHEET_ID = "123VexBVR3y9o6f6pnJKJAWV47PBpT0uhnCL9JSGwIBo"
GID = "465082032"
SECRET_PASSWORD = "123"

try:
    if "API_TOKEN" in st.secrets: API_TOKEN = st.secrets["API_TOKEN"]
    if "SHEET_ID" in st.secrets: SHEET_ID = st.secrets["SHEET_ID"]
    if "GID" in st.secrets: GID = st.secrets["GID"]
    if "PASSWORD" in st.secrets: SECRET_PASSWORD = st.secrets["PASSWORD"]
except Exception:
    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —Å–µ–∫—Ä–µ—Ç–æ–≤ –ø—Ä–∏ –ª–æ–∫–∞–ª—å–Ω–æ–º –∑–∞–ø—É—Å–∫–µ, –µ—Å–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–¥–∞–Ω—ã –≤—ã—à–µ
    pass

# –ö–û–ù–°–¢–ê–ù–¢–´
BASE_URL = "https://api.chat2desk.com/v1"
HEADERS = {"Authorization": API_TOKEN}
SHEET_URL = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={GID}"

MAX_WORKERS = 20
TIME_OFFSET = 3

# –°–ü–†–ê–í–û–ß–ù–ò–ö–ò
OPERATORS_MAP = {310507: "–ë–æ—Ç AI", 0: "–°–∏—Å—Ç–µ–º–∞"}
DEPARTMENT_MAPPING = {
    "–ù–∏–∫–∏—Ç–∞ –ü—Ä–∏—Ö–æ–¥—å–∫–æ": "Concierge", 
    "–ê–ª–∏–Ω–∞ –§–µ–¥—É–ª–æ–≤–∞": "–¢—Ä–µ–Ω–µ—Ä",
    "–ò–ª—å—è –ê–≤—Ä–∞–º–æ–≤": "Appointment",
    "–í–∏–∫—Ç–æ—Ä–∏—è –°—É–≤–æ—Ä–æ–≤–∞": "Appointment",
    "–ö–∏—Ä–∏–ª–ª –ú–∏–Ω–∞–µ–≤": "Appointment",
    "–ú–∞—Ä–∏—è –ü–æ–ø–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–°—Ç–∞–Ω–∏—Å–ª–∞–≤ –ë–∞—Å–æ–≤": "Claims",
    "–ú–∏–ª–µ–Ω–∞ –ì–æ–≤–æ—Ä–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ù–∞–¥–µ–∂–¥–∞ –°–º–∏—Ä–Ω–æ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ò—Ä–∏–Ω–∞ –í–µ—Ä–µ–∂–∞–Ω": "Claims",
    "–ù–∞—Ç–∞–ª—å—è –ü–æ–ª–æ–≤–Ω–∏–∫–æ–≤–∞": "Claims",
    "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–í–ª–∞–¥–∏–º–∏—Ä –ê—Å–∞—Ç—Ä—è–Ω": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –ï—Ä–º–∞–∫–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ì–µ—Ç–º–∞–Ω": "SMM",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –ê–Ω–∏—Å–∏–º–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–û–ª—è –¢—Ä—É—â–µ–ª–µ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ê–ª–∏–Ω–∞ –ù–æ–≤–∏–∫–æ–≤–∞": "SMM",
    "–ò–≤–∞–Ω –°–∞–≤–∏—Ü–∫–∏–π": "SMM",
    "–ê–Ω–∞—Å—Ç–∞—Å–∏—è –í–∞–Ω—è–Ω": "SALE",
    "–ü–∞–≤–µ–ª –ù–æ–≤–∏–∫–æ–≤": "SMM",
    "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞ –®–∞–ø–æ–≤–∞–ª": "SMM",
    "–ì–µ–æ—Ä–≥–∏–π –ê—Å—Ç–∞–ø–æ–≤": "Deep_support",
    "–ï–ª–µ–Ω–∞ –ü–∞–Ω–æ–≤–∞": "Deep_support",
    "–¢–∞—Ç—å—è–Ω–∞ –°–æ—à–Ω–∏–∫–æ–≤–∞": "SMM",
    "–í–∏–∫—Ç–æ—Ä–∏—è –í–æ—Ä–æ–Ω—è–∫": "SMM",
    "–ê–Ω–Ω–∞ –ß–µ—Ä–Ω—ã—à–æ–≤–∞": "SMM",
    "–ê–ª–∏–Ω–∞ –†–µ–±—Ä–∏–Ω–∞": "Claims",
    "–ê–ª–µ–Ω–∞ –í–æ—Ä–æ–Ω–∏–Ω–∞": "Claims",
    "–ö—Å–µ–Ω–∏—è –ë—É—Ö–æ–Ω–∏–Ω–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ï–ª–∏–∑–∞–≤–µ—Ç–∞ –î–∞–≤—ã–¥–µ–Ω–∫–æ": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –ö–æ–Ω–¥—Ä–∞—Ç—å–µ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ö—Å–µ–Ω–∏—è –ì–∞–≤—Ä–∏–ª–æ–≤–∞": "Claims",
    "–°–Ω–µ–∂–∞–Ω–∞ –ï—Ñ–∏–º–æ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ê–Ω–∞—Å—Ç–∞—Å–∏—è –ö–∞—Ä–ø–µ–µ–≤–∞": "Claims",
    "–ö—Ä–∏—Å—Ç–∏–Ω–∞ –õ—é–±–∏–Ω–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ù–∞—Ç–∞–ª—å—è –°–µ—Ä–µ–±—Ä—è–∫–æ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ö–ª–∏—à–∏–Ω": "Claims",
    "–ù–∞—Ç–∞–ª—å—è –ë–∞–ª–∞–Ω–¥–∏–Ω–∞": "Claims",
    "–î–∞–Ω–∏–∏–ª –ì—É—Å–µ–≤": "Appointment",
    "–ê–Ω–Ω–∞ –í–ª–∞—Å–µ–Ω–∫–æ–≤–∞": "SMM",
    "–†–µ–≥–∏–Ω–∞ –ê—Ä–µ–Ω–¥—Ç": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –©—É–∫–∏–Ω–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ö—Å–µ–Ω–∏—è –ö—Ä–∏–≤–∫–æ": "Claims",
    "–í–µ—Ä–æ–Ω–∏–∫–∞ –°–æ—Ñ—Ä–æ–Ω–æ–≤–∞": "SMM",
    "–Æ—Ä–∏–π –ö–æ–±–µ–ª–µ–≤": "Claims",
    "–ê—Ä–∏–Ω–∞ –ü—Ä–æ—Ö–æ—Ä–æ–≤–∞": "SMM"
}

CUSTOM_GROUPING = {
    "Cleaner_Payments": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "Penalty": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "Operations": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "Storage": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ"
}

# ==========================================
# 2. –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø
# ==========================================
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    
    if not st.session_state["password_correct"]:
        st.markdown("### üîê –í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É")
        with st.form("credentials"):
            password = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞", type="password")
            submit = st.form_submit_button("–í–æ–π—Ç–∏")
            
            if submit:
                if str(password).strip() == str(SECRET_PASSWORD).strip():
                    st.session_state["password_correct"] = True
                    st.rerun()
                else:
                    st.error("‚õî –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
        return False
    return True

if not check_password():
    st.stop()

# ==========================================
# 3. –§–£–ù–ö–¶–ò–ò API –ò –û–ë–†–ê–ë–û–¢–ö–ò
# ==========================================
def normalize_text(text):
    if not text: return ""
    return str(text).lower().strip().replace("—ë", "–µ")

def find_department_smart(api_name_full):
    clean_api = normalize_text(api_name_full)
    for name, dept in DEPARTMENT_MAPPING.items():
        if normalize_text(name) == clean_api: return dept
    for name_key, dept in DEPARTMENT_MAPPING.items():
        parts = normalize_text(name_key).split()
        if not parts: continue
        if all(part in clean_api for part in parts): return dept
    return "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"

def format_seconds(x):
    if pd.isna(x) or x is None: return "-"
    try:
        val = int(float(x))
        m, s = divmod(val, 60)
        h, m = divmod(m, 60)
        if h > 0: return f"{h}—á {m}–º"
        return f"{m}–º {s}—Å"
    except: return "-"

def process_single_dialog(item, target_start, target_end):
    req_id = item['req_id']
    try:
        r = requests.get(f"{BASE_URL}/requests/{req_id}/messages", headers=HEADERS, params={"limit": 300})
        if r.status_code != 200: return None
        json_data = r.json()
        msgs = json_data if isinstance(json_data, list) else json_data.get('data', [])
        msgs.sort(key=lambda x: x.get('created', 0))
        
        client_waiting_since = None
        stats = {
            'req_id': req_id,
            'participations': set(),
            'operator_speeds': {},
            'op_hours': {}, # –°—é–¥–∞ –±—É–¥–µ–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–æ—Ä—Ç–µ–∂–∏ (–î–∞—Ç–∞, –ß–∞—Å)
            'rating': item.get('rating')
        }
        
        for m in msgs:
            ts = m.get('created')
            if not ts: continue
            dt_utc = pd.to_datetime(ts, unit='s')
            dt_local = dt_utc + timedelta(hours=TIME_OFFSET)
            
            msg_type = m.get('type')
            op_id = m.get('operatorID') or m.get('operator_id')
            
            if msg_type == 'from_client' or msg_type == 'in':
                if client_waiting_since is None: client_waiting_since = dt_local
            
            elif msg_type == 'out' and op_id and op_id != 0 and op_id != 310507:
                 if target_start <= dt_local <= target_end:
                      stats['participations'].add(op_id)
                      
                      if op_id not in stats['op_hours']: stats['op_hours'][op_id] = set()
                      # –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –¥–∞—Ç—É, –∏ —á–∞—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ –¥–Ω—è–º
                      stats['op_hours'][op_id].add((dt_local.date(), dt_local.hour)) 
                      
                      if client_waiting_since:
                          diff = (dt_local - client_waiting_since).total_seconds()
                          if diff > 0:
                              if op_id not in stats['operator_speeds']: 
                                  stats['operator_speeds'][op_id] = []
                              stats['operator_speeds'][op_id].append(diff)
                          client_waiting_since = None
                      
        return stats
    except:
        return None

@st.cache_data(ttl=3600)
def load_api_data_range(start_date, end_date):
    try:
        r = requests.get(f"{BASE_URL}/operators", headers=HEADERS, params={"limit": 1000})
        for op in r.json().get('data', []):
            name = f"{op.get('first_name', '')} {op.get('last_name', '')}".strip()
            if not name: name = op.get('email', str(op['id']))
            OPERATORS_MAP[op['id']] = name
    except: pass
    
    all_active_requests = []
    date_list = pd.date_range(start_date, end_date).strftime("%Y-%m-%d").tolist()
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, d_str in enumerate(date_list):
        status_text.text(f"–°–±–æ—Ä —Å–ø–∏—Å–∫–∞ —á–∞—Ç–æ–≤ –∑–∞ {d_str}...")
        limit = 200; offset = 0
        while offset < 5000:
            try:
                params = {"report": "request_stats", "date": d_str, "limit": limit, "offset": offset}
                r = requests.get(f"{BASE_URL}/statistics", headers=HEADERS, params=params)
                data = r.json().get('data', [])
                if not data: break
                for row in data:
                    rating = row.get('rating_scale_score')
                    if rating == 0 or rating == '0': rating = None
                    all_active_requests.append({'req_id': row['request_id'], 'rating': rating})
                if len(data) < limit: break
                offset += limit
            except: break
        progress_bar.progress((i + 1) / (len(date_list) * 2))

    unique_requests = {v['req_id']: v for v in all_active_requests}.values()
    
    final_rows = []
    all_speeds = {}        
    all_first_speeds = {} 
    
    total = len(unique_requests)
    completed = 0
    
    target_start_global = pd.to_datetime(f"{start_date.strftime('%Y-%m-%d')} 00:00:00")
    target_end_global = pd.to_datetime(f"{end_date.strftime('%Y-%m-%d')} 23:59:59")
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_single_dialog, item, target_start_global, target_end_global): item for item in unique_requests}
        for future in as_completed(futures):
            res = future.result()
            if res and res['participations']:
                for op_id, speeds in res['operator_speeds'].items():
                    if op_id not in all_speeds: all_speeds[op_id] = []
                    all_speeds[op_id].extend(speeds)
                    
                    if speeds:
                        if op_id not in all_first_speeds: all_first_speeds[op_id] = []
                        all_first_speeds[op_id].append(speeds[0])

                for op_id in res['participations']:
                    op_name = OPERATORS_MAP.get(op_id, f"ID {op_id}")
                    dept = find_department_smart(op_name)
                    if dept in CUSTOM_GROUPING: dept = CUSTOM_GROUPING[dept]
                    if dept == "–¢—Ä–µ–Ω–µ—Ä": continue
                    
                    hours = res.get('op_hours', {}).get(op_id, set())
                    if not hours:
                        final_rows.append({
                            'req_id': res['req_id'],
                            'operator_id': op_id,
                            '–û–ø–µ—Ä–∞—Ç–æ—Ä': op_name,
                            '–û—Ç–¥–µ–ª': dept,
                            'rating': res['rating'],
                            '–î–∞—Ç–∞': None,
                            '–ß–∞—Å': -1
                        })
                    else:
                        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∫–æ—Ä—Ç–µ–∂ (–î–∞—Ç–∞, –ß–∞—Å)
                        for d, h in hours: 
                            final_rows.append({
                                'req_id': res['req_id'],
                                'operator_id': op_id,
                                '–û–ø–µ—Ä–∞—Ç–æ—Ä': op_name,
                                '–û—Ç–¥–µ–ª': dept,
                                'rating': res['rating'],
                                '–î–∞—Ç–∞': d, # –¢–µ–ø–µ—Ä—å —É –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏ –µ—Å—Ç—å –¥–∞—Ç–∞
                                '–ß–∞—Å': h
                            })
            
            completed += 1
            if total > 0: 
                current_prog = 0.5 + (completed / total * 0.5)
                progress_bar.progress(min(current_prog, 1.0))
                status_text.text(f"–ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤: {completed}/{total}")
            
    progress_bar.empty(); status_text.empty()
    
    df = pd.DataFrame(final_rows)
    return df, all_speeds, all_first_speeds

def get_dynamics_stats(df, start_date, end_date):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: –æ–±—ä–µ–º –∏ % –∑–∞–∫—Ä—ã—Ç–∏—è –±–æ—Ç–æ–º"""
    mask = (df['–î–∞—Ç–∞'].dt.date >= start_date) & (df['–î–∞—Ç–∞'].dt.date <= end_date)
    period_df = df[mask].copy()
    
    if period_df.empty:
        return pd.DataFrame(columns=['–í—Å–µ–≥–æ', '–ë–æ—Ç_%'])
    
    stats = period_df.groupby('–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è').agg(
        –í—Å–µ–≥–æ=('–î–∞—Ç–∞', 'count'),
        –ó–∞–∫—Ä—ã—Ç–æ_–±–æ—Ç–æ–º=('–°—Ç–∞—Ç—É—Å', lambda x: (x == '–ó–∞–∫—Ä—ã–ª').sum())
    )
    stats['–ë–æ—Ç_%'] = (stats['–ó–∞–∫—Ä—ã—Ç–æ_–±–æ—Ç–æ–º'] / stats['–í—Å–µ–≥–æ'] * 100)
    return stats[['–í—Å–µ–≥–æ', '–ë–æ—Ç_%']]

# ==========================================
# 4. GOOGLE SHEET
# ==========================================
@st.cache_data(ttl=600)
def load_gsheet_data():
    try:
        df = pd.read_csv(SHEET_URL)
        df['–î–∞—Ç–∞'] = pd.to_datetime(df['–î–∞—Ç–∞'], dayfirst=True, errors='coerce')
        df = df.dropna(subset=['–î–∞—Ç–∞'])
        for col in ['–û—Ç–¥–µ–ª', '–°—Ç–∞—Ç—É—Å', '–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è']:
            if col in df.columns: 
                df[col] = df[col].astype(str).str.strip().replace(['nan', ''], '-')
        
        # !!!!!!! –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ó–î–ï–°–¨ !!!!!!!
        # –ï—Å–ª–∏ –¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è "-" –∏–ª–∏ –ø—É—Å—Ç–æ–π, —Ç–æ –±–µ—Ä–µ–º –û—Ç–¥–µ–ª –∏ –ø–∏—à–µ–º "–ü—Ä—è–º–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è [–û—Ç–¥–µ–ª]"
        def fix_topic(row):
            topic = row['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è']
            dept = row['–û—Ç–¥–µ–ª']
            if topic == '-' or topic == '' or topic == 'nan':
                return f"–ü—Ä—è–º–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è {dept}"
            return topic

        df['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'] = df.apply(fix_topic, axis=1)
        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
        
        df['–ß–∞—Å'] = df['–î–∞—Ç–∞'].dt.hour
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Google Sheet: {e}"); return pd.DataFrame()

# ==========================================
# 5. –ò–ù–¢–ï–†–§–ï–ô–°
# ==========================================
st.sidebar.title("–§–∏–ª—å—Ç—Ä—ã")

# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ GSheet
df_gsheet_all = load_gsheet_data()

# --- –ë–õ–û–ö –ë–ï–ó–û–ü–ê–°–ù–´–• –î–ê–¢ (–ß—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ StreamlitAPIException) ---
today = datetime.now().date()

if not df_gsheet_all.empty:
    sheet_min = df_gsheet_all['–î–∞—Ç–∞'].min().date()
    sheet_max = df_gsheet_all['–î–∞—Ç–∞'].max().date()
else:
    sheet_min = today
    sheet_max = today

# –¢—Ä—é–∫: —Ä–∞–∑—Ä–µ—à–∞–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä—é –≤–∏–¥–µ—Ç—å +1 –¥–µ–Ω—å –æ—Ç —Å–µ–≥–æ–¥–Ω—è, 
# —á—Ç–æ–±—ã "—É—Ç—Ä–µ–Ω–Ω–∏–µ" –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –Ω–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞–ª–∏ —Å UTC –≤—Ä–µ–º–µ–Ω–µ–º —Å–µ—Ä–≤–µ—Ä–∞
absolute_max = max(today, sheet_max) + timedelta(days=1)
absolute_min = min(today, sheet_min)

# –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Ç–∞–≤–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É –∏–∑ —Ç–∞–±–ª–∏—Ü—ã, –Ω–æ –Ω–µ –≤—ã—Ö–æ–¥—è –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã
default_val = min(sheet_max, absolute_max)

date_range = st.sidebar.date_input(
    "–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç",
    value=(default_val, default_val),
    min_value=absolute_min,
    max_value=absolute_max
)
# -----------------------------------------------------------------

# –†–∞–∑–±–æ—Ä –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
if isinstance(date_range, tuple) and len(date_range) == 2:
    sel_start, sel_end = date_range
elif isinstance(date_range, tuple) and len(date_range) == 1:
    sel_start = sel_end = date_range[0]
else:
    sel_start = sel_end = date_range

st.sidebar.caption(f"–í—ã–±—Ä–∞–Ω–æ: {sel_start} ‚Äî {sel_end}")

# –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞
if st.sidebar.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ (API)"):
    st.session_state['run_analysis'] = True
    st.cache_data.clear()

# –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –µ—â–µ –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª–∏ ‚Äî —Å—Ç–æ–ø–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–∞–ª—å—à–µ
if 'run_analysis' not in st.session_state:
    st.info("üëà –í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—ã –∏ –Ω–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑'"); st.stop()

# --- –¢–£–¢ –ù–ê–ß–ò–ù–ê–ï–¢–°–Ø –¢–í–û–Ø –õ–û–ì–ò–ö–ê –ì–†–ê–§–ò–ö–û–í –ò KPI ---

# –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ß–ï–†–ï–ó API
df_api, speeds_map, first_speeds_map = load_api_data_range(sel_start, sel_end)

# –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –ø–æ–¥ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –¥–∞—Ç—ã
mask_gsheet = (df_gsheet_all['–î–∞—Ç–∞'].dt.date >= sel_start) & (df_gsheet_all['–î–∞—Ç–∞'].dt.date <= sel_end)
df_gsheet = df_gsheet_all[mask_gsheet].copy()

# –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ KPI
if not df_api.empty: 
    count_human_chats = df_api['req_id'].nunique()
else: 
    count_human_chats = 0

bot_closed_mask = (df_gsheet['–°—Ç–∞—Ç—É—Å'].str.lower() == '–∑–∞–∫—Ä—ã–ª')
count_bot_closed = len(df_gsheet[bot_closed_mask])

auth_mask = (df_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].str.contains('–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞', case=False, na=False))
count_auth = len(df_gsheet[auth_mask])

total_chats_day = count_human_chats + count_bot_closed + count_auth

# --- –í–´–í–û–î –¢–ê–ë–û–í ---
tabs = st.tabs(["KPI", "–ù–∞–≥—Ä—É–∑–∫–∞", "–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª–∞", "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏", "üìà –î–∏–Ω–∞–º–∏–∫–∞", "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö"])

# –î–∞–ª—å—à–µ –∏–¥—É—Ç —Ç–≤–æ–∏ –±–ª–æ–∫–∏ with tabs[0], with tabs[1] –∏ —Ç.–¥.
# (–û–Ω–∏ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –∫–∞–∫ –≤ —Ç–≤–æ–µ–º –∏—Å—Ö–æ–¥–Ω–æ–º –∫–æ–¥–µ)

# --- –í–´–í–û–î –í–°–ï–• –í–ö–õ–ê–î–û–ö (–ü–û–õ–ù–ê–Ø –õ–û–ì–ò–ö–ê) ---
tabs = st.tabs(["KPI", "–ù–∞–≥—Ä—É–∑–∫–∞", "–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª–∞", "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏", "üìà –î–∏–Ω–∞–º–∏–∫–∞", "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö"])

# ==========================================
# TAB 1: KPI (–ú–µ—Ç—Ä–∏–∫–∏ + 2 –î–∏–∞–≥—Ä–∞–º–º—ã)
# ==========================================
with tabs[0]:
    st.subheader("–°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("–í—Å–µ–≥–æ —á–∞—Ç–æ–≤", total_chats_day)
    c2.metric("–õ—é–¥–∏ (API)", count_human_chats)
    c3.metric("–ë–æ—Ç (–ó–∞–∫—Ä—ã–ª)", count_bot_closed)
    c4.metric("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è", count_auth)
    
    st.divider()
    col_pies = st.columns(2)
    with col_pies[0]:
        st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏")
        if total_chats_day > 0:
            fig1, ax1 = plt.subplots(figsize=(4, 4))
            ax1.pie([count_human_chats, count_bot_closed, count_auth], 
                    labels=['–õ—é–¥–∏', '–ë–æ—Ç (–ó–∞–∫—Ä—ã–ª)', '–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è'], 
                    autopct='%1.1f%%', colors=['#66b3ff', '#ff9999', '#99ff99'], startangle=90)
            st.pyplot(fig1, use_container_width=False)
            
    with col_pies[1]:
        st.subheader("–ö–æ–Ω–≤–µ—Ä—Å–∏—è –±–æ—Ç–∞ (–£—á–∞—Å—Ç–∏–µ)")
        bot_participated_df = df_gsheet[df_gsheet['–°—Ç–∞—Ç—É—Å'].isin(['–ó–∞–∫—Ä—ã–ª', '–ü–µ—Ä–µ–≤–æ–¥'])]
        participated_count = len(bot_participated_df)
        transferred_count = participated_count - count_bot_closed
        
        if participated_count > 0:
            st.caption(f"–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –±–æ—Ç–æ–º: {participated_count}")
            fig2, ax2 = plt.subplots(figsize=(4, 4))
            ax2.pie([count_bot_closed, transferred_count], 
                    labels=['–ó–∞–∫—Ä—ã–ª —Å–∞–º', '–ü–µ—Ä–µ–≤–µ–ª –Ω–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞'], 
                    autopct='%1.1f%%', colors=['#ff9999', '#ffcc99'], startangle=90)
            st.pyplot(fig2, use_container_width=False)
        else:
            st.write("–ë–æ—Ç –Ω–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª –≤ –¥–∏–∞–ª–æ–≥–∞—Ö –∑–∞ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥.")

# ==========================================
# TAB 2: LOAD (–ù–∞–≥—Ä—É–∑–∫–∞ + 2 –¢–µ–ø–ª–æ–≤—ã–µ –∫–∞—Ä—Ç—ã)
# ==========================================
with tabs[1]:
    st.subheader("–ù–∞–≥—Ä—É–∑–∫–∞ –ø–æ –æ—Ç–¥–µ–ª–∞–º (–î–∞–Ω–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç–∞)")
    if not df_api.empty:
        dept_load = df_api.groupby('–û—Ç–¥–µ–ª')['req_id'].nunique().sort_values(ascending=False).reset_index()
        dept_load.columns = ['–û—Ç–¥–µ–ª', '–ö–æ–ª-–≤–æ —á–∞—Ç–æ–≤']
        c_table, c_heat = st.columns([1, 2])
        with c_table: st.dataframe(dept_load, hide_index=True, use_container_width=True)
        with c_heat:
            st.write("**–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞: –û—Ç–¥–µ–ª vs –ß–∞—Å (–î–∞–Ω–Ω—ã–µ API)**")
            hm_df = df_api[df_api['–ß–∞—Å'].between(0, 23)]
            if not hm_df.empty:
                hm_data = hm_df.groupby(['–û—Ç–¥–µ–ª', '–ß–∞—Å'])['req_id'].nunique().unstack(fill_value=0)
                hm_data = hm_data.reindex(columns=range(24), fill_value=0)
                hm_data['Total'] = hm_data.sum(axis=1)
                hm_data = hm_data.sort_values('Total', ascending=False).drop(columns='Total')
                fig_hm, ax_hm = plt.subplots(figsize=(10, len(hm_data)*0.5+2))
                sns.heatmap(hm_data, annot=True, fmt="d", cmap="YlOrRd", cbar=False, ax=ax_hm)
                ax_hm.set_xlabel("–ß–∞—Å –¥–Ω—è")
                st.pyplot(fig_hm)

    st.divider()
    st.subheader("–¢–µ–º–∞—Ç–∏–∫–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–í–°–ï –æ–±—Ä–∞—â–µ–Ω–∏—è)")
    topics_df = df_gsheet[~df_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].str.contains('–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è', na=False)].copy()
    if not topics_df.empty:
        top_topics = topics_df['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].value_counts().nlargest(15).index
        topics_df_top = topics_df[topics_df['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].isin(top_topics)]
        hm_topic = topics_df_top.groupby(['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è', '–ß–∞—Å']).size().unstack(fill_value=0)
        hm_topic = hm_topic.reindex(columns=range(24), fill_value=0)
        hm_topic['Total'] = hm_topic.sum(axis=1)
        hm_topic = hm_topic.sort_values('Total', ascending=False).drop(columns='Total')
        fig_top_hm, ax_top_hm = plt.subplots(figsize=(12, len(hm_topic)*0.6+2))
        sns.heatmap(hm_topic, annot=True, fmt="d", cmap="Blues", cbar=False, ax=ax_top_hm)
        st.pyplot(fig_top_hm)

# ==========================================
# TAB 3: DEPT ANALYSIS (–° –ª–æ–≥–∏–∫–æ–π –¢–∏–º–ª–∏–¥–æ–≤)
# ==========================================
with tabs[2]:
    st.subheader("–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –æ—Ç–¥–µ–ª—É")
    if not df_api.empty:
        all_depts = sorted(df_api['–û—Ç–¥–µ–ª'].unique())
        selected_dept = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç–¥–µ–ª", all_depts, key="dept_analysis_select_vfinal")
        
        if selected_dept:
            dept_data = df_api[df_api['–û—Ç–¥–µ–ª'] == selected_dept].copy()
            TL_NAMES = ["–ß–µ—Ä–Ω—ã—à–µ–≤–∞", "–ì–µ—Ç–º–∞–Ω", "–í–ª–∞—Å–µ–Ω–∫–æ–≤–∞"]
            dept_data['is_tl'] = dept_data['–û–ø–µ—Ä–∞—Ç–æ—Ä'].apply(lambda x: any(tl.lower() in str(x).lower() for tl in TL_NAMES))

            if '–î–∞—Ç–∞' in dept_data.columns:
                daily_chats = dept_data.groupby('–î–∞—Ç–∞')['req_id'].nunique()
                daily_ops = dept_data[~dept_data['is_tl']].groupby('–î–∞—Ç–∞')['operator_id'].nunique()
                daily_stats = pd.DataFrame({'–ß–∞—Ç–æ–≤': daily_chats, '–°–ø–µ—Ü–æ–≤': daily_ops}).reset_index().fillna(0)
                daily_stats['–ù–∞–≥—Ä—É–∑–∫–∞'] = daily_stats.apply(lambda r: round(r['–ß–∞—Ç–æ–≤'] / r['–°–ø–µ—Ü–æ–≤'], 1) if r['–°–ø–µ—Ü–æ–≤'] > 0 else r['–ß–∞—Ç–æ–≤'], axis=1)
                
                c1, c2 = st.columns(2)
                c1.metric("–í—Å–µ–≥–æ —á–∞—Ç–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥ (—Å –¢–õ)", dept_data['req_id'].nunique())
                c2.metric("–°—Ä. –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ 1 —Å–ø–µ—Ü–∞", f"{daily_stats['–ù–∞–≥—Ä—É–∑–∫–∞'].mean():.1f}")
                
                st.write("#### –ü–æ—Å—É—Ç–æ—á–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –æ—Ç–¥–µ–ª–∞")
                st.dataframe(daily_stats.sort_values('–î–∞—Ç–∞', ascending=False), use_container_width=True, hide_index=True)

            st.write("#### –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤")
            specialist_stats = []
            op_list = dept_data.groupby(['operator_id', '–û–ø–µ—Ä–∞—Ç–æ—Ä', 'is_tl']).agg(chats=('req_id', 'nunique')).reset_index().sort_values('chats', ascending=False)
            
            for _, row in op_list.iterrows():
                op_id, op_name, is_tl, cnt = row['operator_id'], row['–û–ø–µ—Ä–∞—Ç–æ—Ä'], row['is_tl'], row['chats']
                s_first = np.median(first_speeds_map.get(op_id, [])) if first_speeds_map.get(op_id) else None
                s_avg = np.median(speeds_map.get(op_id, [])) if speeds_map.get(op_id) else None
                op_ratings = pd.to_numeric(dept_data[dept_data['operator_id'] == op_id]['rating'], errors='coerce').dropna()
                specialist_stats.append({
                    "–†–æ–ª—å": "‚≠ê Team Lead" if is_tl else "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç",
                    "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç": f"‚≠ê {op_name.upper()}" if is_tl else op_name,
                    "–ß–∞—Ç—ã": cnt, "1-—è —Å–∫–æ—Ä–æ—Å—Ç—å": format_seconds(s_first),
                    "–°—Ä. —Å–∫–æ—Ä–æ—Å—Ç—å": format_seconds(s_avg), "–†–µ–π—Ç–∏–Ω–≥": f"{op_ratings.mean():.2f}" if not op_ratings.empty else "-"
                })
            
            df_spec = pd.DataFrame(specialist_stats)
            st.dataframe(df_spec.style.apply(lambda r: ['background-color: #e3f2fd; font-weight: bold']*len(r) if "Team Lead" in r['–†–æ–ª—å'] else ['']*len(r), axis=1), use_container_width=True, hide_index=True)

# ==========================================
# TAB 4: –ö–ê–¢–ï–ì–û–†–ò–ò (–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π Plotly)
# ==========================================
with tabs[3]:
    st.subheader("üìä –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –æ–±—Ä–∞—â–µ–Ω–∏–π")
    sub_tab1, sub_tab2 = st.tabs(["üìã –ü–æ–ª–Ω–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è", "üìà –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¢–û–ü-15"])
    if not df_gsheet.empty:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Plotly
        df_analysis = df_gsheet.copy()
        df_analysis['–†–µ–∑—É–ª—å—Ç–∞—Ç'] = df_analysis.apply(lambda r: '–ë–æ—Ç —Å–ø—Ä–∞–≤–∏–ª—Å—è' if r['–°—Ç–∞—Ç—É—Å'] == '–ó–∞–∫—Ä—ã–ª' else (f"–ü–µ—Ä–µ–≤–æ–¥: {r['–ü—Ä–∏—á–∏–Ω–∞ –ø–µ—Ä–µ–≤–æ–¥–∞']}" if r['–°—Ç–∞—Ç—É—Å'] == '–ü–µ—Ä–µ–≤–æ–¥' and r['–ü—Ä–∏—á–∏–Ω–∞ –ø–µ—Ä–µ–≤–æ–¥–∞'] in ['–¢—Ä–µ–±—É–µ—Ç —Å—Ü–µ–Ω–∞—Ä–∏–π', '–ù–µ –∑–Ω–∞–µ—Ç –æ—Ç–≤–µ—Ç', '–õ–∏–º–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–π'] else '–ü–µ—Ä–µ–≤–æ–¥: –ü—Ä–æ—á–µ–µ'), axis=1)

        with sub_tab1:
            stats = df_gsheet.groupby(['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è', '–°—Ç–∞—Ç—É—Å']).size().unstack(fill_value=0)
            stats['–í—Å–µ–≥–æ'] = stats.sum(axis=1)
            for c in ['–ó–∞–∫—Ä—ã–ª', '–ü–µ—Ä–µ–≤–æ–¥']: 
                if c not in stats.columns: stats[c] = 0
            stats['–ë–æ—Ç(‚úì)'] = (stats['–ó–∞–∫—Ä—ã–ª'] / stats['–í—Å–µ–≥–æ'] * 100).map('{:.1f}%'.format)
            stats['–ë–æ—Ç(‚Üí)'] = (stats['–ü–µ—Ä–µ–≤–æ–¥'] / stats['–í—Å–µ–≥–æ'] * 100).map('{:.1f}%'.format)
            st.dataframe(stats[['–í—Å–µ–≥–æ', '–ë–æ—Ç(‚úì)', '–ë–æ—Ç(‚Üí)']].sort_values('–í—Å–µ–≥–æ', ascending=False).reset_index(), use_container_width=True, hide_index=True)

        with sub_tab2:
            top_names = df_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].value_counts().nlargest(15).index
            plot_data = df_analysis[df_analysis['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].isin(top_names)].groupby(['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è', '–†–µ–∑—É–ª—å—Ç–∞—Ç']).size().reset_index(name='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
            fig = px.bar(plot_data, x="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", y="–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è", color="–†–µ–∑—É–ª—å—Ç–∞—Ç", orientation='h', text_auto=True, category_orders={"–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è": top_names.tolist()})
            fig.update_layout(barmode='stack', height=700, hovermode="y unified")
            st.plotly_chart(fig, use_container_width=True)

# ==========================================
# TAB 5: –î–ò–ù–ê–ú–ò–ö–ê (–í—ã–±–æ—Ä –ø–µ—Ä–∏–æ–¥–∞ + –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)
# ==========================================
with tabs[4]:
    st.subheader("üìà –î–∏–Ω–∞–º–∏–∫–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π")
    with st.expander("‚ÑπÔ∏è –õ–æ–≥–∏–∫–∞ —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ü–∏–∏"):
        st.markdown("| –ú–µ—Ç—Ä–∏–∫–∞ | –¢—Ä–µ–Ω–¥ | –¶–≤–µ—Ç | –°—Ç–∞—Ç—É—Å |\n| :--- | :--- | :--- | :--- |\n| **V (Volume)** | –†–æ—Å—Ç (+) | üî¥ Red | –ö–æ–ª-–≤–æ –æ–±—Ä–∞—â–µ–Ω–∏–π —É–≤–µ–ª–∏—á–∏–ª–æ—Å—å |\n| **V (Volume)** | –°–Ω–∏–∂–µ–Ω–∏–µ (-) | üü¢ Green | –ö–æ–ª-–≤–æ –æ–±—Ä–∞—â–µ–Ω–∏–π —É–º–µ–Ω—å—à–∏–ª–æ—Å—å |\n| **B (Bot)** | –†–æ—Å—Ç (+) | üü¢ Green | –†–æ—Å—Ç % –∑–∞–∫—Ä—ã—Ç–∏—è —á–∞—Ç–æ–≤ –±–æ—Ç–æ–º |\n| **B (Bot)** | –°–Ω–∏–∂–µ–Ω–∏–µ (-) | üî¥ Red | –ü–∞–¥–µ–Ω–∏–µ % –∑–∞–∫—Ä—ã—Ç–∏—è —á–∞—Ç–æ–≤ –±–æ—Ç–æ–º |")

    compare_mode = st.selectbox("–†–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:", ["–î–µ–Ω—å –∫ –¥–Ω—é", "–ù–µ–¥–µ–ª—è –∫ –Ω–µ–¥–µ–ª–µ", "–ú–µ—Å—è—Ü –∫ –º–µ—Å—è—Ü—É", "–°–≤–æ–π –ø–µ—Ä–∏–æ–¥"], index=1)
    today = datetime.now().date()
    # (–ó–¥–µ—Å—å –±–ª–æ–∫ —Ä–∞—Å—á–µ—Ç–∞ curr_start, curr_end, prev_start, prev_end –∫–∞–∫ –≤ –∫–æ–¥–µ –≤—ã—à–µ)
    # ... —É–ø—Ä–æ—â–µ–Ω–Ω–æ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ ...
    curr_start, curr_end = today - timedelta(days=7), today
    prev_start, prev_end = curr_start - timedelta(days=7), curr_start - timedelta(days=1)

    if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"):
        s_curr = get_dynamics_stats(df_gsheet_all, curr_start, curr_end)
        s_prev = get_dynamics_stats(df_gsheet_all, prev_start, prev_end)
        df_dyn = s_curr.join(s_prev, lsuffix='_curr', rsuffix='_prev', how='outer').fillna(0).sort_values('–í—Å–µ–≥–æ_curr', ascending=False)
        
        def calc_v2(row):
            v_pct = ((row['–í—Å–µ–≥–æ_curr'] / row['–í—Å–µ–≥–æ_prev'] - 1) * 100) if row['–í—Å–µ–≥–æ_prev'] > 0 else 0
            b_pp = row['–ë–æ—Ç_%_curr'] - row['–ë–æ—Ç_%_prev']
            return pd.Series([f"{int(row['–í—Å–µ–≥–æ_curr'])}\n({row['–ë–æ—Ç_%_curr']:.1f}%)", f"{int(row['–í—Å–µ–≥–æ_prev'])}\n({row['–ë–æ—Ç_%_prev']:.1f}%)", f"{'üî¥' if v_pct > 0 else 'üü¢'} V: {v_pct:+.1f}%\n{'üü¢' if b_pp > 0 else 'üî¥'} B: {b_pp:+.1f}–ø–ø"])

        res = df_dyn.apply(calc_v2, axis=1)
        res.columns = ['–¢–µ–∫—É—â–∏–π –ø–µ—Ä–∏–æ–¥', '–ü—Ä–æ—à–ª—ã–π –ø–µ—Ä–∏–æ–¥', '–î–∏–Ω–∞–º–∏–∫–∞ (V –∏ B)']
        st.dataframe(res, use_container_width=True, height=600)

# ==========================================
# TAB 6: –ë–ê–ó–ê –î–ê–ù–ù–´–•
# ==========================================
with tabs[5]:
    st.subheader("üóÑÔ∏è –ü–æ–ª–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö")
    if not df_gsheet.empty:
        st.write(f"–ó–∞–ø–∏—Å–µ–π: {len(df_gsheet)}")
        st.dataframe(df_gsheet, use_container_width=True)