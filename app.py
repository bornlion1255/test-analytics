import streamlit as st
import pandas as pd
import numpy as np
import requests
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px  
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==========================================
# 1. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨
# ==========================================
st.set_page_config(page_title="SLA Dashboard Hybrid", layout="wide")

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–µ–∫—Ä–µ—Ç—ã –Ω–∞–ø—Ä—è–º—É—é. 
# –ï—Å–ª–∏ –∏—Ö –Ω–µ—Ç –≤ st.secrets, –ø—Ä–æ–≥—Ä–∞–º–º–∞ –≤—ã–¥–∞—Å—Ç –æ—à–∏–±–∫—É ‚Äî —ç—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ, —á–µ–º —É—Ç–µ—á–∫–∞ —Ç–æ–∫–µ–Ω–∞.
try:
    API_TOKEN = st.secrets["API_TOKEN"]
    SHEET_ID  = st.secrets["SHEET_ID"]
    GID       = st.secrets["GID"]
    SECRET_PASSWORD = st.secrets["PASSWORD"]
except KeyError as e:
    st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –í —Å–µ–∫—Ä–µ—Ç–∞—Ö Streamlit –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ {e}")
    st.stop()

# –ö–û–ù–°–¢–ê–ù–¢–´ (—Ç–µ–ø–µ—Ä—å –æ–Ω–∏ —á–∏—Å—Ç—ã–µ)
BASE_URL = "https://api.chat2desk.com/v1"
HEADERS  = {"Authorization": API_TOKEN}
SHEET_URL = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={GID}"

MAX_WORKERS = 20
TIME_OFFSET = 3

# –°–ü–†–ê–í–û–ß–ù–ò–ö–ò
OPERATORS_MAP = {310507: "–ë–æ—Ç AI", 0: "–°–∏—Å—Ç–µ–º–∞"}
DEPARTMENT_MAPPING = {
    "–ù–∏–∫–∏—Ç–∞ –ü—Ä–∏—Ö–æ–¥—å–∫–æ": "Concierge", 
    "–ê–ª–∏–Ω–∞ –§–µ–¥—É–ª–æ–≤–∞": "–¢—Ä–µ–Ω–µ—Ä",
    "–ò–ª—å—è –ê–≤—Ä–∞–º–æ–≤": "Appointment",
    "–í–∏–∫—Ç–æ—Ä–∏—è –°—É–≤–æ—Ä–æ–≤–∞": "Appointment",
    "–ö–∏—Ä–∏–ª–ª –ú–∏–Ω–∞–µ–≤": "Appointment",
    "–ú–∞—Ä–∏—è –ü–æ–ø–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–°—Ç–∞–Ω–∏—Å–ª–∞–≤ –ë–∞—Å–æ–≤": "Claims",
    "–ú–∏–ª–µ–Ω–∞ –ì–æ–≤–æ—Ä–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ù–∞–¥–µ–∂–¥–∞ –°–º–∏—Ä–Ω–æ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ò—Ä–∏–Ω–∞ –í–µ—Ä–µ–∂–∞–Ω": "Claims",
    "–ù–∞—Ç–∞–ª—å—è –ü–æ–ª–æ–≤–Ω–∏–∫–æ–≤–∞": "Claims",
    "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–í–ª–∞–¥–∏–º–∏—Ä –ê—Å–∞—Ç—Ä—è–Ω": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –ï—Ä–º–∞–∫–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ì–µ—Ç–º–∞–Ω": "SMM",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –ê–Ω–∏—Å–∏–º–æ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–û–ª—è –¢—Ä—É—â–µ–ª–µ–≤–∞": "–ë–µ–∑ –æ—Ç–¥–µ–ª–∞",
    "–ê–ª–∏–Ω–∞ –ù–æ–≤–∏–∫–æ–≤–∞": "SMM",
    "–ò–≤–∞–Ω –°–∞–≤–∏—Ü–∫–∏–π": "SMM",
    "–ê–Ω–∞—Å—Ç–∞—Å–∏—è –í–∞–Ω—è–Ω": "SALE",
    "–ü–∞–≤–µ–ª –ù–æ–≤–∏–∫–æ–≤": "SMM",
    "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞ –®–∞–ø–æ–≤–∞–ª": "SMM",
    "–ì–µ–æ—Ä–≥–∏–π –ê—Å—Ç–∞–ø–æ–≤": "Deep_support",
    "–ï–ª–µ–Ω–∞ –ü–∞–Ω–æ–≤–∞": "Deep_support",
    "–¢–∞—Ç—å—è–Ω–∞ –°–æ—à–Ω–∏–∫–æ–≤–∞": "SMM",
    "–í–∏–∫—Ç–æ—Ä–∏—è –í–æ—Ä–æ–Ω—è–∫": "SMM",
    "–ê–Ω–Ω–∞ –ß–µ—Ä–Ω—ã—à–æ–≤–∞": "SMM",
    "–ê–ª–∏–Ω–∞ –†–µ–±—Ä–∏–Ω–∞": "Claims",
    "–ê–ª–µ–Ω–∞ –í–æ—Ä–æ–Ω–∏–Ω–∞": "Claims",
    "–ö—Å–µ–Ω–∏—è –ë—É—Ö–æ–Ω–∏–Ω–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ï–ª–∏–∑–∞–≤–µ—Ç–∞ –î–∞–≤—ã–¥–µ–Ω–∫–æ": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –ö–æ–Ω–¥—Ä–∞—Ç—å–µ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ö—Å–µ–Ω–∏—è –ì–∞–≤—Ä–∏–ª–æ–≤–∞": "Claims",
    "–°–Ω–µ–∂–∞–Ω–∞ –ï—Ñ–∏–º–æ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ê–Ω–∞—Å—Ç–∞—Å–∏—è –ö–∞—Ä–ø–µ–µ–≤–∞": "Claims",
    "–ö—Ä–∏—Å—Ç–∏–Ω–∞ –õ—é–±–∏–Ω–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ù–∞—Ç–∞–ª—å—è –°–µ—Ä–µ–±—Ä—è–∫–æ–≤–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ö–ª–∏—à–∏–Ω": "Claims",
    "–ù–∞—Ç–∞–ª—å—è –ë–∞–ª–∞–Ω–¥–∏–Ω–∞": "Claims",
    "–î–∞–Ω–∏–∏–ª –ì—É—Å–µ–≤": "Appointment",
    "–ê–Ω–Ω–∞ –í–ª–∞—Å–µ–Ω–∫–æ–≤–∞": "SMM",
    "–†–µ–≥–∏–Ω–∞ –ê—Ä–µ–Ω–¥—Ç": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞ –©—É–∫–∏–Ω–∞": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "–ö—Å–µ–Ω–∏—è –ö—Ä–∏–≤–∫–æ": "Claims",
    "–í–µ—Ä–æ–Ω–∏–∫–∞ –°–æ—Ñ—Ä–æ–Ω–æ–≤–∞": "SMM",
    "–Æ—Ä–∏–π –ö–æ–±–µ–ª–µ–≤": "Claims",
    "–ê—Ä–∏–Ω–∞ –ü—Ä–æ—Ö–æ—Ä–æ–≤–∞": "SMM"
}

CUSTOM_GROUPING = {
    "Cleaner_Payments": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "Penalty": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "Operations": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ",
    "Storage": "–°–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ"
}

# ==========================================
# 2. –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø
# ==========================================
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    
    if not st.session_state["password_correct"]:
        st.markdown("### üîê –í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É")
        with st.form("credentials"):
            password = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞", type="password")
            submit = st.form_submit_button("–í–æ–π—Ç–∏")
            
            if submit:
                if str(password).strip() == str(SECRET_PASSWORD).strip():
                    st.session_state["password_correct"] = True
                    st.rerun()
                else:
                    st.error("‚õî –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
        return False
    return True

if not check_password():
    st.stop()

# ==========================================
# 3. –§–£–ù–ö–¶–ò–ò API –ò –û–ë–†–ê–ë–û–¢–ö–ò
# ==========================================
def normalize_text(text):
    if not text: return ""
    return str(text).lower().strip().replace("—ë", "–µ")

def find_department_smart(api_name_full):
    clean_api = normalize_text(api_name_full)
    for name, dept in DEPARTMENT_MAPPING.items():
        if normalize_text(name) == clean_api: return dept
    for name_key, dept in DEPARTMENT_MAPPING.items():
        parts = normalize_text(name_key).split()
        if not parts: continue
        if all(part in clean_api for part in parts): return dept
    return "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"

def format_seconds(x):
    if pd.isna(x) or x is None: return "-"
    try:
        val = int(float(x))
        m, s = divmod(val, 60)
        h, m = divmod(m, 60)
        if h > 0: return f"{h}—á {m}–º"
        return f"{m}–º {s}—Å"
    except: return "-"

def process_single_dialog(item, target_start, target_end):
    req_id = item['req_id']
    try:
        r = requests.get(f"{BASE_URL}/requests/{req_id}/messages", headers=HEADERS, params={"limit": 300})
        if r.status_code != 200: return None
        json_data = r.json()
        msgs = json_data if isinstance(json_data, list) else json_data.get('data', [])
        msgs.sort(key=lambda x: x.get('created', 0))
        
        client_waiting_since = None
        stats = {
            'req_id': req_id,
            'participations': set(),
            'operator_speeds': {},
            'op_hours': {}, # –°—é–¥–∞ –±—É–¥–µ–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–æ—Ä—Ç–µ–∂–∏ (–î–∞—Ç–∞, –ß–∞—Å)
            'rating': item.get('rating')
        }
        
        for m in msgs:
            ts = m.get('created')
            if not ts: continue
            dt_utc = pd.to_datetime(ts, unit='s')
            dt_local = dt_utc + timedelta(hours=TIME_OFFSET)
            
            msg_type = m.get('type')
            op_id = m.get('operatorID') or m.get('operator_id')
            
            if msg_type == 'from_client' or msg_type == 'in':
                if client_waiting_since is None: client_waiting_since = dt_local
            
            elif msg_type == 'out' and op_id and op_id != 0 and op_id != 310507:
                 if target_start <= dt_local <= target_end:
                      stats['participations'].add(op_id)
                      
                      if op_id not in stats['op_hours']: stats['op_hours'][op_id] = set()
                      # –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –¥–∞—Ç—É, –∏ —á–∞—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ –¥–Ω—è–º
                      stats['op_hours'][op_id].add((dt_local.date(), dt_local.hour)) 
                      
                      if client_waiting_since:
                          diff = (dt_local - client_waiting_since).total_seconds()
                          if diff > 0:
                              if op_id not in stats['operator_speeds']: 
                                  stats['operator_speeds'][op_id] = []
                              stats['operator_speeds'][op_id].append(diff)
                          client_waiting_since = None
                      
        return stats
    except:
        return None

@st.cache_data(ttl=3600)
def load_api_data_range(start_date, end_date):
    try:
        r = requests.get(f"{BASE_URL}/operators", headers=HEADERS, params={"limit": 1000})
        for op in r.json().get('data', []):
            name = f"{op.get('first_name', '')} {op.get('last_name', '')}".strip()
            if not name: name = op.get('email', str(op['id']))
            OPERATORS_MAP[op['id']] = name
    except: pass
    
    all_active_requests = []
    date_list = pd.date_range(start_date, end_date).strftime("%Y-%m-%d").tolist()
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, d_str in enumerate(date_list):
        status_text.text(f"–°–±–æ—Ä —Å–ø–∏—Å–∫–∞ —á–∞—Ç–æ–≤ –∑–∞ {d_str}...")
        limit = 200; offset = 0
        while offset < 5000:
            try:
                params = {"report": "request_stats", "date": d_str, "limit": limit, "offset": offset}
                r = requests.get(f"{BASE_URL}/statistics", headers=HEADERS, params=params)
                data = r.json().get('data', [])
                if not data: break
                for row in data:
                    rating = row.get('rating_scale_score')
                    if rating == 0 or rating == '0': rating = None
                    all_active_requests.append({'req_id': row['request_id'], 'rating': rating})
                if len(data) < limit: break
                offset += limit
            except: break
        progress_bar.progress((i + 1) / (len(date_list) * 2))

    unique_requests = {v['req_id']: v for v in all_active_requests}.values()
    
    final_rows = []
    all_speeds = {}        
    all_first_speeds = {} 
    
    total = len(unique_requests)
    completed = 0
    
    target_start_global = pd.to_datetime(f"{start_date.strftime('%Y-%m-%d')} 00:00:00")
    target_end_global = pd.to_datetime(f"{end_date.strftime('%Y-%m-%d')} 23:59:59")
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_single_dialog, item, target_start_global, target_end_global): item for item in unique_requests}
        for future in as_completed(futures):
            res = future.result()
            if res and res['participations']:
                for op_id, speeds in res['operator_speeds'].items():
                    if op_id not in all_speeds: all_speeds[op_id] = []
                    all_speeds[op_id].extend(speeds)
                    
                    if speeds:
                        if op_id not in all_first_speeds: all_first_speeds[op_id] = []
                        all_first_speeds[op_id].append(speeds[0])

                for op_id in res['participations']:
                    op_name = OPERATORS_MAP.get(op_id, f"ID {op_id}")
                    dept = find_department_smart(op_name)
                    if dept in CUSTOM_GROUPING: dept = CUSTOM_GROUPING[dept]
                    if dept == "–¢—Ä–µ–Ω–µ—Ä": continue
                    
                    hours = res.get('op_hours', {}).get(op_id, set())
                    if not hours:
                        final_rows.append({
                            'req_id': res['req_id'],
                            'operator_id': op_id,
                            '–û–ø–µ—Ä–∞—Ç–æ—Ä': op_name,
                            '–û—Ç–¥–µ–ª': dept,
                            'rating': res['rating'],
                            '–î–∞—Ç–∞': None,
                            '–ß–∞—Å': -1
                        })
                    else:
                        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∫–æ—Ä—Ç–µ–∂ (–î–∞—Ç–∞, –ß–∞—Å)
                        for d, h in hours: 
                            final_rows.append({
                                'req_id': res['req_id'],
                                'operator_id': op_id,
                                '–û–ø–µ—Ä–∞—Ç–æ—Ä': op_name,
                                '–û—Ç–¥–µ–ª': dept,
                                'rating': res['rating'],
                                '–î–∞—Ç–∞': d, # –¢–µ–ø–µ—Ä—å —É –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏ –µ—Å—Ç—å –¥–∞—Ç–∞
                                '–ß–∞—Å': h
                            })
            
            completed += 1
            if total > 0: 
                current_prog = 0.5 + (completed / total * 0.5)
                progress_bar.progress(min(current_prog, 1.0))
                status_text.text(f"–ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤: {completed}/{total}")
            
    progress_bar.empty(); status_text.empty()
    
    df = pd.DataFrame(final_rows)
    return df, all_speeds, all_first_speeds

def get_dynamics_stats(df, start_date, end_date):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: –æ–±—ä–µ–º –∏ % –∑–∞–∫—Ä—ã—Ç–∏—è –±–æ—Ç–æ–º"""
    mask = (df['–î–∞—Ç–∞'].dt.date >= start_date) & (df['–î–∞—Ç–∞'].dt.date <= end_date)
    period_df = df[mask].copy()
    
    if period_df.empty:
        return pd.DataFrame(columns=['–í—Å–µ–≥–æ', '–ë–æ—Ç_%'])
    
    stats = period_df.groupby('–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è').agg(
        –í—Å–µ–≥–æ=('–î–∞—Ç–∞', 'count'),
        –ó–∞–∫—Ä—ã—Ç–æ_–±–æ—Ç–æ–º=('–°—Ç–∞—Ç—É—Å', lambda x: (x == '–ó–∞–∫—Ä—ã–ª').sum())
    )
    stats['–ë–æ—Ç_%'] = (stats['–ó–∞–∫—Ä—ã—Ç–æ_–±–æ—Ç–æ–º'] / stats['–í—Å–µ–≥–æ'] * 100)
    return stats[['–í—Å–µ–≥–æ', '–ë–æ—Ç_%']]

# ==========================================
# 4. GOOGLE SHEET
# ==========================================
@st.cache_data(ttl=600)
def load_gsheet_data():
    try:
        df = pd.read_csv(SHEET_URL)
        df['–î–∞—Ç–∞'] = pd.to_datetime(df['–î–∞—Ç–∞'], dayfirst=True, errors='coerce')
        df = df.dropna(subset=['–î–∞—Ç–∞'])
        for col in ['–û—Ç–¥–µ–ª', '–°—Ç–∞—Ç—É—Å', '–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è']:
            if col in df.columns: 
                df[col] = df[col].astype(str).str.strip().replace(['nan', ''], '-')
        
        # !!!!!!! –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ó–î–ï–°–¨ !!!!!!!
        # –ï—Å–ª–∏ –¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è "-" –∏–ª–∏ –ø—É—Å—Ç–æ–π, —Ç–æ –±–µ—Ä–µ–º –û—Ç–¥–µ–ª –∏ –ø–∏—à–µ–º "–ü—Ä—è–º–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è [–û—Ç–¥–µ–ª]"
        def fix_topic(row):
            topic = row['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è']
            dept = row['–û—Ç–¥–µ–ª']
            if topic == '-' or topic == '' or topic == 'nan':
                return f"–ü—Ä—è–º–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è {dept}"
            return topic

        df['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'] = df.apply(fix_topic, axis=1)
        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
        
        df['–ß–∞—Å'] = df['–î–∞—Ç–∞'].dt.hour
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Google Sheet: {e}"); return pd.DataFrame()

# ==========================================
# 5. –ò–ù–¢–ï–†–§–ï–ô–°
# ==========================================
st.sidebar.title("–§–∏–ª—å—Ç—Ä—ã")

# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ GSheet
df_gsheet_all = load_gsheet_data()

# --- –ë–õ–û–ö –ë–ï–ó–û–ü–ê–°–ù–´–• –î–ê–¢ (–ß—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ StreamlitAPIException) ---
today = datetime.now().date()

if not df_gsheet_all.empty:
    sheet_min = df_gsheet_all['–î–∞—Ç–∞'].min().date()
    sheet_max = df_gsheet_all['–î–∞—Ç–∞'].max().date()
else:
    sheet_min = today
    sheet_max = today

# –¢—Ä—é–∫: —Ä–∞–∑—Ä–µ—à–∞–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä—é –≤–∏–¥–µ—Ç—å +1 –¥–µ–Ω—å –æ—Ç —Å–µ–≥–æ–¥–Ω—è, 
# —á—Ç–æ–±—ã "—É—Ç—Ä–µ–Ω–Ω–∏–µ" –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –Ω–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞–ª–∏ —Å UTC –≤—Ä–µ–º–µ–Ω–µ–º —Å–µ—Ä–≤–µ—Ä–∞
absolute_max = max(today, sheet_max) + timedelta(days=1)
absolute_min = min(today, sheet_min)

# –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Ç–∞–≤–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É –∏–∑ —Ç–∞–±–ª–∏—Ü—ã, –Ω–æ –Ω–µ –≤—ã—Ö–æ–¥—è –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã
default_val = min(sheet_max, absolute_max)

date_range = st.sidebar.date_input(
    "–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç",
    value=(default_val, default_val),
    min_value=absolute_min,
    max_value=absolute_max
)
# -----------------------------------------------------------------

# –†–∞–∑–±–æ—Ä –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
if isinstance(date_range, tuple) and len(date_range) == 2:
    sel_start, sel_end = date_range
elif isinstance(date_range, tuple) and len(date_range) == 1:
    sel_start = sel_end = date_range[0]
else:
    sel_start = sel_end = date_range

st.sidebar.caption(f"–í—ã–±—Ä–∞–Ω–æ: {sel_start} ‚Äî {sel_end}")

# –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞
if st.sidebar.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ (API)"):
    st.session_state['run_analysis'] = True
    st.cache_data.clear()

# –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –µ—â–µ –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª–∏ ‚Äî —Å—Ç–æ–ø–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–∞–ª—å—à–µ
if 'run_analysis' not in st.session_state:
    st.info("üëà –í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—ã –∏ –Ω–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑'"); st.stop()

# --- –¢–£–¢ –ù–ê–ß–ò–ù–ê–ï–¢–°–Ø –¢–í–û–Ø –õ–û–ì–ò–ö–ê –ì–†–ê–§–ò–ö–û–í –ò KPI ---

# –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ß–ï–†–ï–ó API
df_api, speeds_map, first_speeds_map = load_api_data_range(sel_start, sel_end)

# –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –ø–æ–¥ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –¥–∞—Ç—ã
mask_gsheet = (df_gsheet_all['–î–∞—Ç–∞'].dt.date >= sel_start) & (df_gsheet_all['–î–∞—Ç–∞'].dt.date <= sel_end)
df_gsheet = df_gsheet_all[mask_gsheet].copy()

# –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ KPI
if not df_api.empty: 
    count_human_chats = df_api['req_id'].nunique()
else: 
    count_human_chats = 0

bot_closed_mask = (df_gsheet['–°—Ç–∞—Ç—É—Å'].str.lower() == '–∑–∞–∫—Ä—ã–ª')
count_bot_closed = len(df_gsheet[bot_closed_mask])

auth_mask = (df_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].str.contains('–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞', case=False, na=False))
count_auth = len(df_gsheet[auth_mask])

total_chats_day = count_human_chats + count_bot_closed + count_auth

# --- –í–´–í–û–î –¢–ê–ë–û–í ---
tabs = st.tabs(["KPI", "–ù–∞–≥—Ä—É–∑–∫–∞", "–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª–∞", "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏", "üìà –î–∏–Ω–∞–º–∏–∫–∞", "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö"])

# –î–∞–ª—å—à–µ –∏–¥—É—Ç —Ç–≤–æ–∏ –±–ª–æ–∫–∏ with tabs[0], with tabs[1] –∏ —Ç.–¥.
# (–û–Ω–∏ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –∫–∞–∫ –≤ —Ç–≤–æ–µ–º –∏—Å—Ö–æ–¥–Ω–æ–º –∫–æ–¥–µ)

# TAB 1: KPI
with tabs[0]:
    st.subheader("–°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("–í—Å–µ–≥–æ —á–∞—Ç–æ–≤", total_chats_day)
    c2.metric("–õ—é–¥–∏ (API)", count_human_chats)
    c3.metric("–ë–æ—Ç (–ó–∞–∫—Ä—ã–ª)", count_bot_closed)
    c4.metric("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è", count_auth)
    
    st.divider()
    col_pies = st.columns(2)
    with col_pies[0]:
        st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏")
        if total_chats_day > 0:
            fig1, ax1 = plt.subplots(figsize=(4, 4))
            ax1.pie([count_human_chats, count_bot_closed, count_auth], 
                    labels=['–õ—é–¥–∏', '–ë–æ—Ç (–ó–∞–∫—Ä—ã–ª)', '–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è'], 
                    autopct='%1.1f%%', colors=['#66b3ff', '#ff9999', '#99ff99'], startangle=90)
            st.pyplot(fig1, use_container_width=False)
            
    with col_pies[1]:
        st.subheader("–ö–æ–Ω–≤–µ—Ä—Å–∏—è –±–æ—Ç–∞ (–¢–∞–º –≥–¥–µ –ø—Ä–∏–Ω–∏–º–∞–ª —É—á–∞—Å—Ç–∏–µ)")
        bot_participated_df = df_gsheet[df_gsheet['–°—Ç–∞—Ç—É—Å'].isin(['–ó–∞–∫—Ä—ã–ª', '–ü–µ—Ä–µ–≤–æ–¥'])]
        participated_count = len(bot_participated_df)
        transferred_count = participated_count - count_bot_closed
        
        if participated_count > 0:
            st.caption(f"–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –±–æ—Ç–æ–º: {participated_count}")
            fig2, ax2 = plt.subplots(figsize=(4, 4))
            ax2.pie([count_bot_closed, transferred_count], 
                    labels=['–ó–∞–∫—Ä—ã–ª —Å–∞–º', '–ü–µ—Ä–µ–≤–µ–ª –Ω–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞'], 
                    autopct='%1.1f%%', colors=['#ff9999', '#ffcc99'], startangle=90)
            st.pyplot(fig2, use_container_width=False)
        else:
            st.write("–ë–æ—Ç –Ω–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª –≤ –¥–∏–∞–ª–æ–≥–∞—Ö –∑–∞ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥.")

# TAB 2: LOAD
with tabs[1]:
    st.subheader("–ù–∞–≥—Ä—É–∑–∫–∞ –ø–æ –æ—Ç–¥–µ–ª–∞–º (–î–∞–Ω–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç–∞)")
    if not df_api.empty:
        dept_load = df_api.groupby('–û—Ç–¥–µ–ª')['req_id'].nunique().sort_values(ascending=False).reset_index()
        dept_load.columns = ['–û—Ç–¥–µ–ª', '–ö–æ–ª-–≤–æ —á–∞—Ç–æ–≤']
        c_table, c_heat = st.columns([1, 2])
        with c_table: st.dataframe(dept_load, hide_index=True, use_container_width=True)
        with c_heat:
            st.write("**–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞: –û—Ç–¥–µ–ª vs –ß–∞—Å (–î–∞–Ω–Ω—ã–µ API)**")
            
            hm_df = df_api[df_api['–ß–∞—Å'].between(0, 23)]
            
            if not hm_df.empty:
                hm_data = hm_df.groupby(['–û—Ç–¥–µ–ª', '–ß–∞—Å'])['req_id'].nunique().unstack(fill_value=0)
                hm_data = hm_data.reindex(columns=range(24), fill_value=0)
                hm_data['Total'] = hm_data.sum(axis=1)
                hm_data = hm_data.sort_values('Total', ascending=False).drop(columns='Total')

                fig_hm, ax_hm = plt.subplots(figsize=(10, len(hm_data)*0.5+2))
                sns.heatmap(hm_data, annot=True, fmt="d", cmap="YlOrRd", cbar=False, ax=ax_hm)
                ax_hm.set_xlabel("–ß–∞—Å –¥–Ω—è")
                st.pyplot(fig_hm)
            else:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —á–∞—Å–∞–º –≤ API.")

    st.divider()
    st.subheader("–¢–µ–º–∞—Ç–∏–∫–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
    # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é, "-" —É–∂–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω
    topics_df = df_gsheet[~df_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].str.contains('–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è', na=False)].copy()
    
    if not topics_df.empty:
        top_topics = topics_df['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].value_counts().nlargest(15).index
        topics_df_top = topics_df[topics_df['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].isin(top_topics)]
        hm_topic = topics_df_top.groupby(['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è', '–ß–∞—Å']).size().unstack(fill_value=0)
        hm_topic = hm_topic.reindex(columns=range(24), fill_value=0)
        hm_topic['Total'] = hm_topic.sum(axis=1)
        hm_topic = hm_topic.sort_values('Total', ascending=False).drop(columns='Total')
        
        fig2, ax2 = plt.subplots(figsize=(12, len(hm_topic)*0.6+2))
        sns.heatmap(hm_topic, annot=True, fmt="d", cmap="Blues", cbar=False, ax=ax2)
        st.pyplot(fig2)

# ==========================================
# TAB 3: DEPT ANALYSIS (TL LOGIC + EVALUATIONS)
# ==========================================
with tabs[2]:
    st.subheader("–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –æ—Ç–¥–µ–ª—É")
    if not df_api.empty:
        all_depts = sorted(df_api['–û—Ç–¥–µ–ª'].unique())
        selected_dept = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç–¥–µ–ª", all_depts, key="dept_analysis_v7")
        
        if selected_dept:
            dept_data = df_api[df_api['–û—Ç–¥–µ–ª'] == selected_dept].copy()
            
            # 1. –°–ß–ò–¢–ê–ï–ú –†–ï–ô–¢–ò–ù–ì –û–¢–î–ï–õ–ê (—É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ req_id, —á—Ç–æ–±—ã –Ω–µ –∑–∞–¥–≤–∞–∏–≤–∞—Ç—å –æ—Ü–µ–Ω–∫–∏)
            unique_ratings = pd.to_numeric(dept_data.drop_duplicates('req_id')['rating'], errors='coerce').dropna()
            d_rate = unique_ratings.mean() if not unique_ratings.empty else 0.0
            d_rate_cnt = len(unique_ratings)
            d_rate_str = f"{d_rate:.2f}" if d_rate_cnt > 0 else "-"
            
            # 2. –°–ß–ò–¢–ê–ï–ú –°–ö–û–†–û–°–¢–¨ –û–¢–î–ï–õ–ê
            dept_speeds = []
            operators_in_dept = dept_data['operator_id'].unique()
            for op_id in operators_in_dept:
                if op_id in speeds_map: dept_speeds.extend(speeds_map[op_id])
            d_med = np.median(dept_speeds) if dept_speeds else None

            # 3. –õ–û–ì–ò–ö–ê –¢–ò–ú–õ–ò–î–û–í
            TL_ROOTS = ["—á–µ—Ä–Ω—ã—à", "–≥–µ—Ç–º–∞–Ω", "–≤–ª–∞—Å–µ–Ω–∫–æ–≤"]
            dept_data['is_tl'] = dept_data['–û–ø–µ—Ä–∞—Ç–æ—Ä'].apply(
                lambda x: any(normalize_text(tl) in normalize_text(x) for tl in TL_ROOTS)
            )

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –æ–±—â–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
            st.markdown(f"""
            ### üìÇ {selected_dept}: {dept_data['req_id'].nunique()} —á–∞—Ç–æ–≤
            **(–ü–æ –æ—Ç–¥–µ–ª—É: –°—Ä. —Å–∫–æ—Ä–æ—Å—Ç—å: {format_seconds(d_med)} | –†–µ–π—Ç–∏–Ω–≥: {d_rate_str} ({d_rate_cnt} —à—Ç.))**
            """)

            # 4. –ü–û–°–£–¢–û–ß–ù–ê–Ø –ù–ê–ì–†–£–ó–ö–ê
            if '–î–∞—Ç–∞' in dept_data.columns:
                daily_chats = dept_data.groupby('–î–∞—Ç–∞')['req_id'].nunique()
                daily_ops = dept_data[~dept_data['is_tl']].groupby('–î–∞—Ç–∞')['operator_id'].nunique()
                
                daily_stats = pd.DataFrame({'–ß–∞—Ç–æ–≤': daily_chats, '–°–ø–µ—Ü–æ–≤': daily_ops}).reset_index().fillna(0)
                daily_stats['–ù–∞–≥—Ä—É–∑–∫–∞'] = daily_stats.apply(
                    lambda r: round(r['–ß–∞—Ç–æ–≤'] / r['–°–ø–µ—Ü–æ–≤'], 1) if r['–°–ø–µ—Ü–æ–≤'] > 0 else r['–ß–∞—Ç–æ–≤'], axis=1
                )
                
                st.write("#### –ü–æ—Å—É—Ç–æ—á–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –æ—Ç–¥–µ–ª–∞")
                st.dataframe(daily_stats.sort_values('–î–∞—Ç–∞', ascending=False), use_container_width=True, hide_index=True)

            st.divider()

            # 5. –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ü–ï–¶–ò–ê–õ–ò–°–¢–û–í (–° –û–¶–ï–ù–ö–ê–ú–ò)
            st.write("#### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤")
            op_list = dept_data.groupby(['operator_id', '–û–ø–µ—Ä–∞—Ç–æ—Ä', 'is_tl']).agg(
                chats=('req_id', 'nunique')
            ).reset_index().sort_values('chats', ascending=False)
            
            spec_rows = []
            for _, row in op_list.iterrows():
                op_id = row['operator_id']
                
                # –ú–µ–¥–∏–∞–Ω–Ω—ã–µ —Å–∫–æ—Ä–æ—Å—Ç–∏
                s_first_speeds = first_speeds_map.get(op_id, [])
                s_first_med = np.median(s_first_speeds) if s_first_speeds else None
                s_avg = np.median(speeds_map.get(op_id, [])) if speeds_map.get(op_id) else None
                
                # –õ–∏—á–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
                op_ratings = pd.to_numeric(
                    dept_data[dept_data['operator_id'] == op_id]['rating'], 
                    errors='coerce'
                ).dropna()
                s_rate_val = op_ratings.mean() if not op_ratings.empty else 0.0
                s_rate_cnt = len(op_ratings)
                
                spec_rows.append({
                    "–†–æ–ª—å": "‚≠ê Team Lead" if row['is_tl'] else "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç",
                    "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç": f"‚≠ê {row['–û–ø–µ—Ä–∞—Ç–æ—Ä'].upper()}" if row['is_tl'] else row['–û–ø–µ—Ä–∞—Ç–æ—Ä'],
                    "–ß–∞—Ç—ã": row['chats'],
                    "1-—è —Å–∫–æ—Ä.": format_seconds(s_first_med),
                    "–°—Ä. —Å–∫–æ—Ä.": format_seconds(s_avg),
                    "–†–µ–π—Ç–∏–Ω–≥": f"{s_rate_val:.2f}" if s_rate_cnt > 0 else "-",
                    "–û—Ü–µ–Ω–æ–∫": s_rate_cnt
                })
            
            df_spec = pd.DataFrame(spec_rows)
            st.dataframe(
                df_spec.style.apply(lambda r: ['background-color: #e3f2fd; font-weight: bold']*len(r) if "Team Lead" in r['–†–æ–ª—å'] else ['']*len(r), axis=1),
                use_container_width=True, 
                hide_index=True
            )

            st.divider()
            
            # 6. –¢–ï–ú–ê–¢–ò–ö–ò –ò–ó GSHEET
            st.subheader("–¢–µ–º–∞—Ç–∏–∫–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π (GSheet)")
            dept_gsheet = df_gsheet[df_gsheet['–û—Ç–¥–µ–ª'] == selected_dept]
            if not dept_gsheet.empty:
                cat_counts = dept_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].value_counts().reset_index()
                cat_counts.columns = ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ö–æ–ª-–≤–æ']
                
                total_chats_period = dept_data['req_id'].nunique()
                cat_counts['–î–æ–ª—è'] = (cat_counts['–ö–æ–ª-–≤–æ'] / total_chats_period * 100).map('{:.1f}%'.format)
                st.dataframe(cat_counts, use_container_width=True, hide_index=True)
    else:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö API. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑.")

# ==========================================
# TAB 4: –ö–ê–¢–ï–ì–û–†–ò–ò (–î–ï–¢–ê–õ–¨–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê)
# ==========================================
with tabs[3]:
    st.subheader("üìä –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –æ–±—Ä–∞—â–µ–Ω–∏–π")
    
    # –°–æ–∑–¥–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –≤–∫–ª–∞–¥–∫–∏ –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    sub_tab1, sub_tab2 = st.tabs(["üìã –ü–æ–ª–Ω–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è", "üìà –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¢–û–ü-15"])

    if not df_gsheet.empty:
        
        # --- 1. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ---
        def group_result_detailed(row):
            if row['–°—Ç–∞—Ç—É—Å'] == '–ó–∞–∫—Ä—ã–ª':
                return '–ë–æ—Ç —Å–ø—Ä–∞–≤–∏–ª—Å—è'
            elif row['–°—Ç–∞—Ç—É—Å'] == '–ü–µ—Ä–µ–≤–æ–¥':
                reason = str(row.get('–ü—Ä–∏—á–∏–Ω–∞ –ø–µ—Ä–µ–≤–æ–¥–∞', '–î—Ä—É–≥–æ–µ'))
                if reason in ['–¢—Ä–µ–±—É–µ—Ç —Å—Ü–µ–Ω–∞—Ä–∏–π', '–ù–µ –∑–Ω–∞–µ—Ç –æ—Ç–≤–µ—Ç', '–õ–∏–º–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–π']:
                    return f"–ü–µ—Ä–µ–≤–æ–¥: {reason}"
                return "–ü–µ—Ä–µ–≤–æ–¥: –ü—Ä–æ—á–µ–µ"
            return "–ë–µ–∑ —Å—Ç–∞—Ç—É—Å–∞"

        df_analysis = df_gsheet.copy()
        df_analysis['–†–µ–∑—É–ª—å—Ç–∞—Ç'] = df_analysis.apply(group_result_detailed, axis=1)

        # --- 2. SUB-TAB 1: –¢–ê–ë–õ–ò–¶–ê –° –î–ï–¢–ê–õ–ò–ó–ê–¶–ò–ï–ô ---
        with sub_tab1:
            st.write("#### –ü–æ–ª–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
            
            # –ë–∞–∑–æ–≤–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞
            stats = df_gsheet.groupby(['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è', '–°—Ç–∞—Ç—É—Å']).size().unstack(fill_value=0)
            stats['–í—Å–µ–≥–æ'] = stats.sum(axis=1)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            for c in ['–ó–∞–∫—Ä—ã–ª', '–ü–µ—Ä–µ–≤–æ–¥']: 
                if c not in stats.columns: stats[c] = 0
                
            stats['–ë–æ—Ç(‚úì)'] = (stats['–ó–∞–∫—Ä—ã–ª'] / stats['–í—Å–µ–≥–æ'] * 100).map('{:.1f}%'.format)
            stats['–ë–æ—Ç(‚Üí)'] = (stats['–ü–µ—Ä–µ–≤–æ–¥'] / stats['–í—Å–µ–≥–æ'] * 100).map('{:.1f}%'.format)

            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ (—Ç–æ, —á—Ç–æ —Ç—ã —Ö–æ—Ç–µ–ª –≤–µ—Ä–Ω—É—Ç—å)
            def get_cat_details(row):
                transferred = row.get('–ü–µ—Ä–µ–≤–æ–¥', 0)
                if transferred == 0: return "‚Äî"
                cat_reasons = df_gsheet[(df_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'] == row.name) & (df_gsheet['–°—Ç–∞—Ç—É—Å'] == '–ü–µ—Ä–µ–≤–æ–¥')]
                r_counts = cat_reasons['–ü—Ä–∏—á–∏–Ω–∞ –ø–µ—Ä–µ–≤–æ–¥–∞'].value_counts()
                return "\n".join([f"‚Ä¢ {r}: {(count/transferred*100):.0f}%" for r, count in r_counts.items() if count > 0])

            stats['–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞'] = stats.apply(get_cat_details, axis=1)
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü—ã
            final_table = stats[['–í—Å–µ–≥–æ', '–ë–æ—Ç(‚úì)', '–ë–æ—Ç(‚Üí)', '–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞']].sort_values('–í—Å–µ–≥–æ', ascending=False).reset_index()
            
            st.dataframe(final_table, use_container_width=True, hide_index=True)

        # --- 3. SUB-TAB 2: –¶–í–ï–¢–ù–û–ô –ì–†–ê–§–ò–ö (–ü–†–ò–ß–ò–ù–´ –ü–ï–†–ï–í–û–î–ê) ---
        with sub_tab2:
            st.write("#### –¢–æ–ø-15 –æ–±—Ä–∞—â–µ–Ω–∏–π –≤ —Ä–∞–∑—Ä–µ–∑–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
            
            top_names = df_gsheet['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].value_counts().nlargest(15).index
            df_plot = df_analysis[df_analysis['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è'].isin(top_names)]

            plot_data = df_plot.groupby(['–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è', '–†–µ–∑—É–ª—å—Ç–∞—Ç']).size().reset_index(name='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
            
            # –¶–≤–µ—Ç–æ–≤–∞—è –∫–∞—Ä—Ç–∞ (—Ç–≤–æ—è –ª—é–±–∏–º–∞—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–∞—è —Å—Ö–µ–º–∞)
            color_map = {
                '–ë–æ—Ç —Å–ø—Ä–∞–≤–∏–ª—Å—è': '#26A69A',           # –ë–∏—Ä—é–∑–æ–≤—ã–π
                '–ü–µ—Ä–µ–≤–æ–¥: –ù–µ –∑–Ω–∞–µ—Ç –æ—Ç–≤–µ—Ç': '#FF5252',  # –ö—Ä–∞—Å–Ω—ã–π
                '–ü–µ—Ä–µ–≤–æ–¥: –¢—Ä–µ–±—É–µ—Ç —Å—Ü–µ–Ω–∞—Ä–∏–π': '#FFAB40', # –û—Ä–∞–Ω–∂–µ–≤—ã–π
                '–ü–µ—Ä–µ–≤–æ–¥: –õ–∏–º–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–π': '#7C4DFF', # –§–∏–æ–ª–µ—Ç–æ–≤—ã–π
                '–ü–µ—Ä–µ–≤–æ–¥: –ü—Ä–æ—á–µ–µ': '#90A4AE',          # –°–µ—Ä—ã–π
                '–ë–µ–∑ —Å—Ç–∞—Ç—É—Å–∞': '#CFD8DC'                # –°–≤–µ—Ç–ª–æ-—Å–µ—Ä—ã–π
            }

            fig = px.bar(
                plot_data, 
                x="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", 
                y="–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è", 
                color="–†–µ–∑—É–ª—å—Ç–∞—Ç",
                orientation='h',
                color_discrete_map=color_map,
                text_auto=True,
                category_orders={"–¢–∏–ø –æ–±—Ä–∞—â–µ–Ω–∏—è": top_names.tolist()} 
            )

            fig.update_layout(
                barmode='stack',
                height=700, 
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                hovermode="y unified" 
            )
            
            fig.update_yaxes(title="")
            fig.update_xaxes(title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∏–∞–ª–æ–≥–æ–≤")

            st.plotly_chart(fig, use_container_width=True)

    else:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –¥–∞—Ç—ã –≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ö.")

# ==========================================
# TAB 5: –î–ò–ù–ê–ú–ò–ö–ê (–ü–ï–†–ò–û–î –ë -> –ü–ï–†–ò–û–î –ê + –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø)
# ==========================================
with tabs[4]:
    st.subheader("üìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏–∫–∏: –ü—Ä–æ—à–ª–æ–µ vs –ù–∞—Å—Ç–æ—è—â–µ–µ")
    
    # 1. –õ–µ–≥–µ–Ω–¥–∞ (–û–ø–∏—Å–∞–Ω–∏–µ –ª–æ–≥–∏–∫–∏)
    with st.expander("‚ÑπÔ∏è –õ–æ–≥–∏–∫–∞ —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ü–∏–∏", expanded=False):
        st.markdown("""
        | –ú–µ—Ç—Ä–∏–∫–∞ | –¢—Ä–µ–Ω–¥ | –¶–≤–µ—Ç | –°—Ç–∞—Ç—É—Å |
        | :--- | :--- | :--- | :--- |
        | **V (Volume)** | –†–æ—Å—Ç (+) | üî¥ Red | –ö–æ–ª-–≤–æ –æ–±—Ä–∞—â–µ–Ω–∏–π –≤—ã—Ä–æ—Å–ª–æ |
        | **V (Volume)** | –°–Ω–∏–∂–µ–Ω–∏–µ (-) | üü¢ Green | –ö–æ–ª-–≤–æ –æ–±—Ä–∞—â–µ–Ω–∏–π —É–ø–∞–ª–æ |
        | **B (Bot)** | –†–æ—Å—Ç (+) | üü¢ Green | –†–æ—Å—Ç % –∑–∞–∫—Ä—ã—Ç–∏–µ —á–∞—Ç–æ–≤ –±–æ—Ç–æ–º |
        | **B (Bot)** | –°–Ω–∏–∂–µ–Ω–∏–µ (-) | üî¥ Red | –ü–∞–¥–µ–Ω–∏–µ % –∑–∞–∫—Ä—ã—Ç–∏–µ —á–∞—Ç–æ–≤ –±–æ—Ç–æ–º |
        """)

    # 2. –í—ã–±–æ—Ä –ø–µ—Ä–∏–æ–¥–æ–≤ (–°–Ω–∞—á–∞–ª–∞ –ü–†–û–®–õ–û–ï, –ø–æ—Ç–æ–º –¢–ï–ö–£–©–ï–ï)
    st.write("#### 1. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–µ—Ä–∏–æ–¥—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    col_past, col_curr = st.columns(2)
    
    today_dyn = datetime.now().date()
    
    with col_past:
        st.markdown("‚è™ **–ü–µ—Ä–∏–æ–¥ –ë (–ü—Ä–æ—à–ª–æ–µ)**")
        range_prev = st.date_input("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ—à–ª—ã–µ –¥–∞—Ç—ã", [today_dyn - timedelta(days=14), today_dyn - timedelta(days=8)], key="dyn_p_b")
        
    with col_curr:
        st.markdown("‚è© **–ü–µ—Ä–∏–æ–¥ –ê (–ù–∞—Å—Ç–æ—è—â–µ–µ)**")
        range_curr = st.date_input("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–∫—É—â–∏–µ –¥–∞—Ç—ã", [today_dyn - timedelta(days=7), today_dyn], key="dyn_p_a")

    # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞
    if st.button("–ü—Ä–æ—Å—á–∏—Ç–∞—Ç—å –¥–∏–Ω–∞–º–∏–∫—É –∏ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", use_container_width=True):
        if len(range_curr) == 2 and len(range_prev) == 2:
            p_s, p_e = range_prev
            c_s, c_e = range_curr
            
            # –†–∞—Å—á–µ—Ç –¥–∞–Ω–Ω—ã—Ö
            stats_p = get_dynamics_stats(df_gsheet_all, p_s, p_e)
            stats_c = get_dynamics_stats(df_gsheet_all, c_s, c_e)

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º (–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–µ–∫—É—â–µ–º—É –æ–±—ä–µ–º—É –ê)
            df_dyn = stats_c.join(stats_p, lsuffix='_curr', rsuffix='_prev', how='outer').fillna(0)
            df_dyn = df_dyn.sort_values('–í—Å–µ–≥–æ_curr', ascending=False)
            
            # –§—É–Ω–∫—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
            def prepare_visual_row(row):
                v_c, v_p = row['–í—Å–µ–≥–æ_curr'], row['–í—Å–µ–≥–æ_prev']
                b_c, b_p = row['–ë–æ—Ç_%_curr'], row['–ë–æ—Ç_%_prev']
                
                # Volume Change
                v_diff = ((v_c / v_p - 1) * 100) if v_p > 0 else (100.0 if v_c > 0 else 0.0)
                v_ico = "üî¥" if v_diff > 0 else "üü¢"
                
                # Bot Change
                b_diff = b_c - b_p
                b_ico = "üü¢" if b_diff > 0 else ("üî¥" if b_diff < 0 else "‚ö™")
                
                return pd.Series([
                    int(v_p), # –ë—ã–ª–æ —á–∞—Ç–æ–≤
                    int(v_c), # –°—Ç–∞–ª–æ —á–∞—Ç–æ–≤
                    f"{v_ico} {v_diff:+.1f}%", # –¢—Ä–µ–Ω–¥ V
                    v_diff, # –î–ª—è –ø–æ–ª–æ—Å–∫–∏ V
                    f"{b_p:.1f}% ‚Üí {b_c:.1f}%", # –ü—É—Ç—å –±–æ—Ç–∞
                    f"{b_ico} {b_diff:+.1f}–ø–ø" # –¢—Ä–µ–Ω–¥ B
                ])

            if not df_dyn.empty:
                res_tab = df_dyn.apply(prepare_visual_row, axis=1)
                res_tab.columns = ['–ë—ã–ª–æ (–ë)', '–°—Ç–∞–ª–æ (–ê)', '–ò–∑–º–µ–Ω–µ–Ω–∏–µ V', '–®–∫–∞–ª–∞ V', '–≠—Ñ—Ñ. –±–æ—Ç–∞ (–ë‚Üí–ê)', '–¢—Ä–µ–Ω–¥ B']
                
                # --- –í–ò–ó–£–ê–õ–¨–ù–û–ï –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï ---
                st.write("#### 2. –ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º column_config –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ–ª–æ—Å–æ–∫
                st.dataframe(
                    res_tab,
                    use_container_width=True,
                    height=600,
                    column_config={
                        "–®–∫–∞–ª–∞ V": st.column_config.BarChartColumn(
                            "–í–∏–∑—É–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç V",
                            help="–ö—Ä–∞—Å–Ω—ã–µ –ø–æ–ª–æ—Å–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π —Ä–æ—Å—Ç –Ω–∞–≥—Ä—É–∑–∫–∏",
                            y_min=-100, y_max=100
                        ),
                        "–ë—ã–ª–æ (–ë)": st.column_config.NumberColumn(format="%d üó®Ô∏è"),
                        "–°—Ç–∞–ª–æ (–ê)": st.column_config.NumberColumn(format="%d üó®Ô∏è")
                    }
                )
                
                # –ö—Ä–∞—Ç–∫–∏–π –∏—Ç–æ–≥
                t_v_c = df_dyn['–í—Å–µ–≥–æ_curr'].sum()
                t_v_p = df_dyn['–í—Å–µ–≥–æ_prev'].sum()
                t_diff = ((t_v_c / t_v_p - 1) * 100) if t_v_p > 0 else 0
                st.metric("–û–±—â–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤—Ö–æ–¥—è—â–µ–≥–æ –ø–æ—Ç–æ–∫–∞", f"{int(t_v_c)} —á–∞—Ç–æ–≤", f"{t_diff:+.1f}%", delta_color="inverse")
            else:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–∞—Ö.")
        else:
            st.error("–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–ª–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–∞—Ç (–Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü).")
# ==========================================
# TAB 6: –ë–ê–ó–ê –î–ê–ù–ù–´–•
# ==========================================
with tabs[5]: # 
    st.subheader("üóÑÔ∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö")
    if not df_gsheet.empty:
        st.write(f"–û—Ç–æ–±—Ä–∞–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df_gsheet)}")
        st.dataframe(df_gsheet, use_container_width=True)
    else:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")